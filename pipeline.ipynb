{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import openai\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, RobertaTokenizer, RobertaTokenizerFast\n",
    "import matplotlib.pyplot as plt\n",
    "from openai import OpenAI\n",
    "def cve_keywordlist(CVE):\n",
    "    cve_query = f\"\"\"I want you to create a proper keyword list for a CVE, I will give you a list of tips for proper keyword list creation which are given below between triple backticks. Then I will give you and example CVE and the example keyword list in JSON, to help you understand the task better. Your result should also have 3 related keywords per item like the example result. Lastly I will give you a CVE and you have to give me the keyword list in JSON format.\n",
    "    Tips: ```\n",
    "    1. Text Normalization: Standardize the text by converting it to lowercase, removing special characters, and expanding abbreviations. This helps in reducing variations in the text.\n",
    "\n",
    "    2. Abstraction: given the CVE description, create an abstraction of it by leaving aside the terms that are too specific (e.g. if a CVE is specifically targeting a cisco router, this detail is not important)\n",
    "\n",
    "    3. Keyword Extraction: Identify and extract key terms and concepts from both the CVE and CWE descriptions. For instance, phrases like \"incorrectly handles a length field\" or \"buffer overflow\" are critical.\n",
    "\n",
    "    ```\n",
    "\n",
    "    CVE_example: {{\n",
    "        \"CVE description\": \"Patient Information Center iX (PICiX) Versions B.02, PerformanceBridge Focal Point Version A.01, IntelliVue patient monitors MX100 IntelliVue X3 and X2 Versions N and prior. The software parses a formatted message or structure but does not handle or incorrectly handles a length field that is inconsistent with the actual length of the associated data, causing the application on the surveillance station to restart.\"\n",
    "    }}      \n",
    "    CVE_example result: {{\n",
    "        \"core_terms\": [\"Parsing Vulnerability\", \"Inconsistent Length Field Handling\", \"Application Restart\"],\n",
    "        \"contextual_terms\": [\"Length field\", \"Inconsistency\", \"Improper handling\" ],\n",
    "        \"consequences\": [\"Unexpected restart\", \"Data length mismatch\", \"Application instability\"]}}\n",
    "\n",
    "    CVE: {json.dumps(CVE, indent=4)}\n",
    "\n",
    "    Give the result like the example result in a JSON list, with proper representation of the keywords list applicable for this CVE.\n",
    "    \"\"\"\n",
    "\n",
    "    #Get CVE keyword list\n",
    "    client = OpenAI(api_key='sk-...')\n",
    "    response = client.chat.completions.create(\n",
    "    # model=\"gpt-4-1106-preview\",\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful cybersecurity expert designed to help me standardize CVE keyword lists, so they can be accurately compared to Common Weakness Enumerations (CWE).\"},\n",
    "        {\"role\": \"user\", \"content\": cve_query},\n",
    "    ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import tqdm\n",
    "def transform_entry(entry):\n",
    "    \n",
    "    try:\n",
    "        cve_processed = json.loads(cve_keywordlist(entry['cve_description']))\n",
    "        transformed_data = {\n",
    "            'cve_id': entry['cve_id'],\n",
    "            'cve_description': entry['cve_description'],\n",
    "            'cve_terms': cve_processed,\n",
    "            'cve_descr_no_subj':entry['cve_descr_no_subj'],\n",
    "            'cve_descr_replaced_subj':entry['cve_descr_replaced_subj'],\n",
    "            'cwe': entry['cwe'],\n",
    "            'cwe_class':entry['cwe_class']\n",
    "            \n",
    "        }\n",
    "        # print(transformed_data)\n",
    "        return transformed_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing entry: {entry}, Error: {e}\")\n",
    "        time.sleep(20)\n",
    "        transform_entry(entry)\n",
    "\n",
    "def transform_json(input_file, output_file, dump_interval=2000):\n",
    "    # Read input JSON file\n",
    "    with open(input_file, 'rb') as infile:\n",
    "        original_json = pickle.load(infile)\n",
    "    transformed_data_list = []\n",
    "    processed_count = 0\n",
    "    # Use ThreadPoolExecutor to parallelize the processing of JSON entries\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        # Submit tasks for each entry in the JSON file\n",
    "        futures = tqdm.tqdm([executor.submit(transform_entry, entry) for entry in original_json])\n",
    "\n",
    "        # Collect results as they become available\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                transformed_data_list.append(result)\n",
    "                processed_count += 1\n",
    "\n",
    "                # Dump to JSON every dump_interval entries\n",
    "                if processed_count % dump_interval == 0:\n",
    "                    with open(output_file, 'wb') as out:\n",
    "                        pickle.dump(transformed_data_list, out)\n",
    "    \n",
    "    # Write the final result to the output file\n",
    "    with open(output_file, 'wb') as out:\n",
    "        pickle.dump(transformed_data_list, out)\n",
    "\n",
    "input_file_path = 'replacement.pickle'\n",
    "output_file_path = 'replacement_with_terms.pickle'\n",
    "transform_json(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verb identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_svos(sentence):\n",
    "    # Process the sentence using spaCy\n",
    "    doc = nlp(sentence)\n",
    "\n",
    "    svos = []\n",
    "    subject = \"\"\n",
    "    for token in doc:\n",
    "        # Check if token is a verb\n",
    "        if token.pos_ == \"VERB\":\n",
    "            # If we already found a subject, add the SVO triple\n",
    "            if subject:\n",
    "                svos.append((subject, token.text, \"\"))\n",
    "                subject = \"\"  # Reset subject for next SVO triple\n",
    "        else:\n",
    "            # Accumulate words before the first verb as subject\n",
    "            subject += token.text + \" \"\n",
    "    return svos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "def transform_json2(input_file, output_file):\n",
    "\n",
    "    with open(input_file, 'rb') as infile:\n",
    "        original_json = pickle.load(infile)\n",
    "\n",
    "    transformed_data_list = []\n",
    "    for entry in tqdm.tqdm(original_json):\n",
    "        sentence = entry['cve_description']\n",
    "        first_subject=\"\"\n",
    "        first_verb=\"\"\n",
    "        svos = extract_svos(sentence)\n",
    "        if svos:\n",
    "            first_subject = svos[0][0]\n",
    "            first_verb = svos[0][1]\n",
    "            verb_index = sentence.find(first_verb)\n",
    "            text_after_subject = sentence[verb_index :].strip()\n",
    "        else:\n",
    "            continue\n",
    "        try:    \n",
    "            transformed_data = {\n",
    "                'cve_id': entry['cve_id'],\n",
    "                'cve_description': entry['cve_description'],\n",
    "                'cve_terms': entry['cve_terms'],\n",
    "                'cve_descr_no_subj':text_after_subject,\n",
    "                'cve_descr_replaced_subj':\"This vulnerability \"+text_after_subject,\n",
    "                'cwe': entry['cwe'],\n",
    "                'cwe_class':entry['cwe_class']\n",
    "            }\n",
    "            transformed_data_list.append(transformed_data)\n",
    "        except:\n",
    "            with open(output_file, 'wb') as out:\n",
    "                json.dump(transformed_data_list, out)\n",
    "     \n",
    " \n",
    "    with open(output_file, 'wb') as out:\n",
    "        pickle.dump(transformed_data_list, out)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings in multithreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3784/3784 [07:47<00:00,  8.09it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "from openai import OpenAI\n",
    "import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "def embed(entry):\n",
    "    modelemb = \"text-embedding-ada-002\"\n",
    "    # Read input JSON file\n",
    "    client = OpenAI(api_key='sk-...')\n",
    "\n",
    "    transformed_data_list = []\n",
    "    \n",
    "    try:    \n",
    "        cve_description_ada = client.embeddings.create(input=[entry['cve_description']], model=modelemb).data[0].embedding\n",
    "        cve_description_no_sub_ada = client.embeddings.create(input=[entry['cve_descr_no_subj']], model=modelemb).data[0].embedding\n",
    "        cve_description_replaced_sub_ada = client.embeddings.create(input=[entry['cve_descr_replaced_subj']], model=modelemb).data[0].embedding\n",
    "        concat_cve_terms= str(entry['cve_terms'][\"core_terms\"] + entry['cve_terms'][\"contextual_terms\"] + entry['cve_terms'][\"consequences\"])\n",
    "        concat_core_contextual= str(entry['cve_terms'][\"core_terms\"] + entry['cve_terms'][\"contextual_terms\"])\n",
    "        concat_core_consequences= str(entry['cve_terms'][\"core_terms\"] + entry['cve_terms'][\"consequences\"])\n",
    "        cve_terms_ada = client.embeddings.create(input=[concat_cve_terms], model=modelemb).data[0].embedding\n",
    "        cve_core_terms_ada = client.embeddings.create(input=[(str(entry['cve_terms'][\"core_terms\"]))], model=modelemb).data[0].embedding\n",
    "        cve_core_contextual_terms_ada = client.embeddings.create(input=[concat_core_contextual], model=modelemb).data[0].embedding\n",
    "        cve_core_consequences_terms_ada = client.embeddings.create(input=[concat_core_consequences], model=modelemb).data[0].embedding\n",
    "        print(concat_cve_terms)\n",
    "        transformed_data = {\n",
    "            'cve_id': entry['cve_id'],\n",
    "            'cve_description': entry['cve_description'],\n",
    "            'cve_terms': entry['cve_terms'],\n",
    "            'cve_descr_no_subj':entry['cve_descr_no_subj'],\n",
    "            'cve_descr_replaced_subj':entry['cve_descr_replaced_subj'],\n",
    "            'cwe': entry['cwe'],\n",
    "            'cwe_class':entry['cwe_class'],\n",
    "            'cve_description_ada_embedding': cve_description_ada\n",
    "            'cve_description_no_subject_ada_embedding': cve_description_no_sub_ada,\n",
    "            'cve_description_replaced_subject_ada_embedding': cve_description_replaced_sub_ada,\n",
    "            'cve_terms_ada_embedding' : cve_terms_ada,\n",
    "            'cve_core_ada_embedding' : cve_core_terms_ada,\n",
    "            'cve_core_contextual_ada_embedding' : cve_core_contextual_terms_ada,\n",
    "            'cve_core_consequences_ada_embedding' : cve_core_consequences_terms_ada\n",
    "        }\n",
    "\n",
    "        transformed_data_list.append(transformed_data)\n",
    "        return transformed_data  # Return the transformed data\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing entry: {entry}, Error: {e}\")\n",
    "        time.sleep(20)\n",
    "        # Don't call transform_entry(entry) here\n",
    "\n",
    "def transform_json(input_file, output_file):\n",
    "\n",
    "    with open(input_file, 'rb') as infile:\n",
    "        original_json = pickle.load(infile)\n",
    "\n",
    "    transformed_data_list = []\n",
    "\n",
    "    # Use ThreadPoolExecutor to parallelize the processing of JSON entries\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        # Submit tasks for each entry in the JSON file\n",
    "        futures = tqdm.tqdm([executor.submit(embed, entry) for entry in original_json])\n",
    "\n",
    "        # Collect results as they become available\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                transformed_data_list.append(result)\n",
    "\n",
    "    # Write the final result to the output file\n",
    "    with open(output_file, 'wb') as out:\n",
    "        pickle.dump(transformed_data_list, out)\n",
    "\n",
    "input_file_path = 'replacement_with_terms2.pickle'\n",
    "output_file_path = 'replacement_with_terms2_core_consequences.pickle'\n",
    "transform_json(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

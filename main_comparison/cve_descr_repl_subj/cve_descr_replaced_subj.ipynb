{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train CVE description with replaced subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "226/226 [==============================] - 1s 3ms/step loss: \n",
      "Epoch 1 - F1 Score: 0.5212\n",
      "Saved best model\n",
      "[0.5211711677862818]\n",
      "2026/2026 [==============================] - 11s 5ms/step - loss: 2.1243 - accuracy: 0.4452 - val_loss: 1.5971 - val_accuracy: 0.5545\n",
      "Epoch 2/40\n",
      "226/226 [==============================] - 1s 2ms/step loss: 1.4\n",
      "Epoch 2 - F1 Score: 0.5772\n",
      "Saved best model\n",
      "[0.5211711677862818, 0.577220215940376]\n",
      "2026/2026 [==============================] - 8s 4ms/step - loss: 1.4646 - accuracy: 0.5922 - val_loss: 1.4112 - val_accuracy: 0.6041\n",
      "Epoch 3/40\n",
      "226/226 [==============================] - 0s 2ms/step loss: 1.330\n",
      "Epoch 3 - F1 Score: 0.6164\n",
      "Saved best model\n",
      "[0.5211711677862818, 0.577220215940376, 0.6164249415229962]\n",
      "2026/2026 [==============================] - 9s 4ms/step - loss: 1.3304 - accuracy: 0.6254 - val_loss: 1.3325 - val_accuracy: 0.6285\n",
      "Epoch 4/40\n",
      "226/226 [==============================] - 0s 2ms/step loss: 1.2534 \n",
      "Epoch 4 - F1 Score: 0.6273\n",
      "Saved best model\n",
      "[0.5211711677862818, 0.577220215940376, 0.6164249415229962, 0.6272713803079761]\n",
      "2026/2026 [==============================] - 9s 4ms/step - loss: 1.2533 - accuracy: 0.6464 - val_loss: 1.2709 - val_accuracy: 0.6400\n",
      "Epoch 5/40\n",
      "226/226 [==============================] - 0s 2ms/step loss: 1.1992 \n",
      "Epoch 5 - F1 Score: 0.6414\n",
      "Saved best model\n",
      "[0.5211711677862818, 0.577220215940376, 0.6164249415229962, 0.6272713803079761, 0.6414149330583327]\n",
      "2026/2026 [==============================] - 9s 4ms/step - loss: 1.1996 - accuracy: 0.6604 - val_loss: 1.2254 - val_accuracy: 0.6511\n",
      "Epoch 6/40\n",
      "226/226 [==============================] - 0s 2ms/step loss: 1.1584 \n",
      "2026/2026 [==============================] - 8s 4ms/step - loss: 1.1584 - accuracy: 0.6713 - val_loss: 1.2233 - val_accuracy: 0.6508\n",
      "Epoch 7/40\n",
      "226/226 [==============================] - 0s 2ms/step loss: 1.1234 - \n",
      "Epoch 7 - F1 Score: 0.6418\n",
      "Saved best model\n",
      "[0.5211711677862818, 0.577220215940376, 0.6164249415229962, 0.6272713803079761, 0.6414149330583327, 0.6399022113639652, 0.6417792978723099]\n",
      "2026/2026 [==============================] - 9s 4ms/step - loss: 1.1235 - accuracy: 0.6801 - val_loss: 1.2068 - val_accuracy: 0.6542\n",
      "Epoch 8/40\n",
      "226/226 [==============================] - 1s 2ms/step loss: 1.092\n",
      "Epoch 8 - F1 Score: 0.6526\n",
      "Saved best model\n",
      "[0.5211711677862818, 0.577220215940376, 0.6164249415229962, 0.6272713803079761, 0.6414149330583327, 0.6399022113639652, 0.6417792978723099, 0.652644035864074]\n",
      "2026/2026 [==============================] - 8s 4ms/step - loss: 1.0922 - accuracy: 0.6889 - val_loss: 1.1802 - val_accuracy: 0.6633\n",
      "Epoch 9/40\n",
      "226/226 [==============================] - 1s 3ms/step los\n",
      "Epoch 9 - F1 Score: 0.6575\n",
      "Saved best model\n",
      "[0.5211711677862818, 0.577220215940376, 0.6164249415229962, 0.6272713803079761, 0.6414149330583327, 0.6399022113639652, 0.6417792978723099, 0.652644035864074, 0.6574615176667699]\n",
      "2026/2026 [==============================] - 9s 5ms/step - loss: 1.0671 - accuracy: 0.6942 - val_loss: 1.1620 - val_accuracy: 0.6697\n",
      "Epoch 10/40\n",
      "226/226 [==============================] - 0s 2ms/step loss: 1.0440 \n",
      "2026/2026 [==============================] - 9s 4ms/step - loss: 1.0434 - accuracy: 0.6982 - val_loss: 1.1673 - val_accuracy: 0.6656\n",
      "Epoch 11/40\n",
      "226/226 [==============================] - 1s 2ms/step loss: 1.0\n",
      "Epoch 11 - F1 Score: 0.6621\n",
      "Saved best model\n",
      "[0.5211711677862818, 0.577220215940376, 0.6164249415229962, 0.6272713803079761, 0.6414149330583327, 0.6399022113639652, 0.6417792978723099, 0.652644035864074, 0.6574615176667699, 0.657386606629364, 0.6621285487505255]\n",
      "2026/2026 [==============================] - 10s 5ms/step - loss: 1.0214 - accuracy: 0.7048 - val_loss: 1.1484 - val_accuracy: 0.6714\n",
      "Epoch 12/40\n",
      "226/226 [==============================] - 1s 3ms/step loss: 0\n",
      "Epoch 12 - F1 Score: 0.6643\n",
      "Saved best model\n",
      "[0.5211711677862818, 0.577220215940376, 0.6164249415229962, 0.6272713803079761, 0.6414149330583327, 0.6399022113639652, 0.6417792978723099, 0.652644035864074, 0.6574615176667699, 0.657386606629364, 0.6621285487505255, 0.6642772045089005]\n",
      "2026/2026 [==============================] - 10s 5ms/step - loss: 0.9990 - accuracy: 0.7088 - val_loss: 1.1554 - val_accuracy: 0.6722\n",
      "Epoch 13/40\n",
      "226/226 [==============================] - 1s 2ms/step loss: 0.978\n",
      "Epoch 13 - F1 Score: 0.6686\n",
      "Saved best model\n",
      "[0.5211711677862818, 0.577220215940376, 0.6164249415229962, 0.6272713803079761, 0.6414149330583327, 0.6399022113639652, 0.6417792978723099, 0.652644035864074, 0.6574615176667699, 0.657386606629364, 0.6621285487505255, 0.6642772045089005, 0.6685928419993981]\n",
      "2026/2026 [==============================] - 9s 4ms/step - loss: 0.9784 - accuracy: 0.7153 - val_loss: 1.1545 - val_accuracy: 0.6718\n",
      "Epoch 14/40\n",
      "226/226 [==============================] - 0s 1ms/step loss: 0.9610 - ac\n",
      "2026/2026 [==============================] - 8s 4ms/step - loss: 0.9609 - accuracy: 0.7194 - val_loss: 1.1576 - val_accuracy: 0.6726\n",
      "Epoch 15/40\n",
      "226/226 [==============================] - 1s 2ms/step loss: 0.9\n",
      "Epoch 15 - F1 Score: 0.6720\n",
      "Saved best model\n",
      "[0.5211711677862818, 0.577220215940376, 0.6164249415229962, 0.6272713803079761, 0.6414149330583327, 0.6399022113639652, 0.6417792978723099, 0.652644035864074, 0.6574615176667699, 0.657386606629364, 0.6621285487505255, 0.6642772045089005, 0.6685928419993981, 0.6680804995929365, 0.6720429702714388]\n",
      "2026/2026 [==============================] - 6s 3ms/step - loss: 0.9429 - accuracy: 0.7247 - val_loss: 1.1301 - val_accuracy: 0.6797\n",
      "Epoch 16/40\n",
      "226/226 [==============================] - 0s 2ms/step loss: 0.9279 - \n",
      "Epoch 16 - F1 Score: 0.6727\n",
      "Saved best model\n",
      "[0.5211711677862818, 0.577220215940376, 0.6164249415229962, 0.6272713803079761, 0.6414149330583327, 0.6399022113639652, 0.6417792978723099, 0.652644035864074, 0.6574615176667699, 0.657386606629364, 0.6621285487505255, 0.6642772045089005, 0.6685928419993981, 0.6680804995929365, 0.6720429702714388, 0.6727235638842428]\n",
      "2026/2026 [==============================] - 7s 3ms/step - loss: 0.9276 - accuracy: 0.7281 - val_loss: 1.1373 - val_accuracy: 0.6765\n",
      "Epoch 17/40\n",
      "226/226 [==============================] - 1s 3ms/step los\n",
      "2026/2026 [==============================] - 9s 4ms/step - loss: 0.9103 - accuracy: 0.7322 - val_loss: 1.1512 - val_accuracy: 0.6786\n",
      "Epoch 18/40\n",
      "226/226 [==============================] - 1s 2ms/step loss: 0.895\n",
      "Epoch 18 - F1 Score: 0.6754\n",
      "Saved best model\n",
      "[0.5211711677862818, 0.577220215940376, 0.6164249415229962, 0.6272713803079761, 0.6414149330583327, 0.6399022113639652, 0.6417792978723099, 0.652644035864074, 0.6574615176667699, 0.657386606629364, 0.6621285487505255, 0.6642772045089005, 0.6685928419993981, 0.6680804995929365, 0.6720429702714388, 0.6727235638842428, 0.6722695980384692, 0.6753657492206752]\n",
      "2026/2026 [==============================] - 9s 4ms/step - loss: 0.8952 - accuracy: 0.7362 - val_loss: 1.1390 - val_accuracy: 0.6807\n",
      "Epoch 19/40\n",
      "226/226 [==============================] - 0s 2ms/step loss: 0.879\n",
      "2026/2026 [==============================] - 7s 4ms/step - loss: 0.8801 - accuracy: 0.7413 - val_loss: 1.1503 - val_accuracy: 0.6767\n",
      "Epoch 20/40\n",
      "226/226 [==============================] - 0s 1ms/step loss: 0.8668 - ac\n",
      "2026/2026 [==============================] - 7s 3ms/step - loss: 0.8669 - accuracy: 0.7445 - val_loss: 1.1527 - val_accuracy: 0.6786\n",
      "Epoch 21/40\n",
      "226/226 [==============================] - 1s 3ms/step loss: 0\n",
      "2026/2026 [==============================] - 8s 4ms/step - loss: 0.8533 - accuracy: 0.7489 - val_loss: 1.1626 - val_accuracy: 0.6760\n",
      "Epoch 22/40\n",
      "226/226 [==============================] - 0s 1ms/step loss: 0.8378 - accu\n",
      "2026/2026 [==============================] - 8s 4ms/step - loss: 0.8377 - accuracy: 0.7524 - val_loss: 1.1850 - val_accuracy: 0.6753\n",
      "Epoch 23/40\n",
      "226/226 [==============================] - 0s 2ms/step loss: 0.8251 - \n",
      "Epoch 23 - F1 Score: 0.6764\n",
      "Saved best model\n",
      "[0.5211711677862818, 0.577220215940376, 0.6164249415229962, 0.6272713803079761, 0.6414149330583327, 0.6399022113639652, 0.6417792978723099, 0.652644035864074, 0.6574615176667699, 0.657386606629364, 0.6621285487505255, 0.6642772045089005, 0.6685928419993981, 0.6680804995929365, 0.6720429702714388, 0.6727235638842428, 0.6722695980384692, 0.6753657492206752, 0.6692345690082262, 0.6702386011834601, 0.6707921620292892, 0.6728351718531678, 0.6764014416980909]\n",
      "2026/2026 [==============================] - 8s 4ms/step - loss: 0.8253 - accuracy: 0.7553 - val_loss: 1.1822 - val_accuracy: 0.6792\n",
      "Epoch 24/40\n",
      "226/226 [==============================] - 1s 2ms/step loss: 0.813\n",
      "Epoch 24 - F1 Score: 0.6775\n",
      "Saved best model\n",
      "[0.5211711677862818, 0.577220215940376, 0.6164249415229962, 0.6272713803079761, 0.6414149330583327, 0.6399022113639652, 0.6417792978723099, 0.652644035864074, 0.6574615176667699, 0.657386606629364, 0.6621285487505255, 0.6642772045089005, 0.6685928419993981, 0.6680804995929365, 0.6720429702714388, 0.6727235638842428, 0.6722695980384692, 0.6753657492206752, 0.6692345690082262, 0.6702386011834601, 0.6707921620292892, 0.6728351718531678, 0.6764014416980909, 0.6775298932179291]\n",
      "2026/2026 [==============================] - 8s 4ms/step - loss: 0.8129 - accuracy: 0.7581 - val_loss: 1.1656 - val_accuracy: 0.6828\n",
      "Epoch 25/40\n",
      "226/226 [==============================] - 0s 1ms/step loss: 0.7999 - accu\n",
      "2026/2026 [==============================] - 7s 4ms/step - loss: 0.7998 - accuracy: 0.7625 - val_loss: 1.2286 - val_accuracy: 0.6756\n",
      "Epoch 26/40\n",
      "226/226 [==============================] - 1s 3ms/step los\n",
      "Epoch 26 - F1 Score: 0.6792\n",
      "Saved best model\n",
      "[0.5211711677862818, 0.577220215940376, 0.6164249415229962, 0.6272713803079761, 0.6414149330583327, 0.6399022113639652, 0.6417792978723099, 0.652644035864074, 0.6574615176667699, 0.657386606629364, 0.6621285487505255, 0.6642772045089005, 0.6685928419993981, 0.6680804995929365, 0.6720429702714388, 0.6727235638842428, 0.6722695980384692, 0.6753657492206752, 0.6692345690082262, 0.6702386011834601, 0.6707921620292892, 0.6728351718531678, 0.6764014416980909, 0.6775298932179291, 0.6667628885891568, 0.6791839953031813]\n",
      "2026/2026 [==============================] - 8s 4ms/step - loss: 0.7880 - accuracy: 0.7633 - val_loss: 1.1832 - val_accuracy: 0.6826\n",
      "Epoch 27/40\n",
      "226/226 [==============================] - 0s 2ms/step loss: 0.7759 \n",
      "2026/2026 [==============================] - 8s 4ms/step - loss: 0.7757 - accuracy: 0.7685 - val_loss: 1.2106 - val_accuracy: 0.6767\n",
      "Epoch 28/40\n",
      "226/226 [==============================] - 0s 1ms/step loss: 0.7637 - accu\n",
      "2026/2026 [==============================] - 7s 4ms/step - loss: 0.7638 - accuracy: 0.7698 - val_loss: 1.2265 - val_accuracy: 0.6700\n",
      "Epoch 29/40\n",
      "226/226 [==============================] - 0s 2ms/step loss: 0.754\n",
      "2026/2026 [==============================] - 8s 4ms/step - loss: 0.7538 - accuracy: 0.7739 - val_loss: 1.2316 - val_accuracy: 0.6757\n",
      "Epoch 30/40\n",
      "226/226 [==============================] - 1s 3ms/step loss:\n",
      "2026/2026 [==============================] - 9s 4ms/step - loss: 0.7428 - accuracy: 0.7769 - val_loss: 1.2221 - val_accuracy: 0.6742\n",
      "Epoch 31/40\n",
      "226/226 [==============================] - 0s 2ms/step loss: 0.7324 - \n",
      "2026/2026 [==============================] - 7s 4ms/step - loss: 0.7321 - accuracy: 0.7803 - val_loss: 1.2273 - val_accuracy: 0.6774\n",
      "Epoch 32/40\n",
      "226/226 [==============================] - 1s 2ms/step loss: 0.7\n",
      "2026/2026 [==============================] - 9s 4ms/step - loss: 0.7198 - accuracy: 0.7850 - val_loss: 1.2490 - val_accuracy: 0.6786\n",
      "Epoch 33/40\n",
      "226/226 [==============================] - 0s 2ms/step loss: 0.710\n",
      "2026/2026 [==============================] - 9s 4ms/step - loss: 0.7107 - accuracy: 0.7872 - val_loss: 1.2532 - val_accuracy: 0.6792\n",
      "Epoch 34/40\n",
      "226/226 [==============================] - 0s 1ms/step loss: 0.6991 - accura\n",
      "2026/2026 [==============================] - 7s 4ms/step - loss: 0.7000 - accuracy: 0.7888 - val_loss: 1.2633 - val_accuracy: 0.6749\n",
      "Epoch 35/40\n",
      "226/226 [==============================] - 0s 1ms/step loss: 0.6900 - accu\n",
      "2026/2026 [==============================] - 5s 2ms/step - loss: 0.6902 - accuracy: 0.7913 - val_loss: 1.2907 - val_accuracy: 0.6751\n",
      "Epoch 36/40\n",
      "226/226 [==============================] - 0s 996us/steposs: 0.6819 - accura\n",
      "2026/2026 [==============================] - 5s 2ms/step - loss: 0.6823 - accuracy: 0.7923 - val_loss: 1.2808 - val_accuracy: 0.6743\n",
      "Epoch 37/40\n",
      "226/226 [==============================] - 0s 998us/steposs: 0.6723 - accura\n",
      "2026/2026 [==============================] - 5s 2ms/step - loss: 0.6723 - accuracy: 0.7976 - val_loss: 1.3037 - val_accuracy: 0.6694\n",
      "Epoch 38/40\n",
      "226/226 [==============================] - 1s 2ms/step loss: 0.661\n",
      "2026/2026 [==============================] - 5s 3ms/step - loss: 0.6618 - accuracy: 0.8007 - val_loss: 1.3295 - val_accuracy: 0.6640\n",
      "Epoch 39/40\n",
      "226/226 [==============================] - 0s 2ms/step loss: 0.6544 - \n",
      "2026/2026 [==============================] - 8s 4ms/step - loss: 0.6544 - accuracy: 0.8025 - val_loss: 1.3212 - val_accuracy: 0.6729\n",
      "Epoch 40/40\n",
      "226/226 [==============================] - 0s 2ms/step loss: 0.6441 - \n",
      "2026/2026 [==============================] - 9s 4ms/step - loss: 0.6444 - accuracy: 0.8034 - val_loss: 1.3513 - val_accuracy: 0.6682\n",
      "402/402 [==============================] - 1s 2ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         119     0.8127    0.4785    0.6024      1070\n",
      "         120     0.3023    0.6633    0.4153       196\n",
      "         125     0.7864    0.7613    0.7736       532\n",
      "         134     0.4483    0.6842    0.5417        19\n",
      "         190     0.4710    0.6900    0.5598       200\n",
      "          20     0.4938    0.2963    0.3704       810\n",
      "         200     0.8011    0.4915    0.6092       590\n",
      "         203     0.6207    0.6667    0.6429        27\n",
      "          22     0.8489    0.7375    0.7893       518\n",
      "         269     0.2023    0.5000    0.2880       106\n",
      "         276     0.1600    0.1875    0.1727        64\n",
      "         287     0.4306    0.6316    0.5121       285\n",
      "         295     0.6500    0.6420    0.6460        81\n",
      "         306     0.3063    0.3617    0.3317        94\n",
      "         312     0.1818    0.2381    0.2062        42\n",
      "         319     0.4727    0.5098    0.4906        51\n",
      "         326     0.3182    0.2258    0.2642        31\n",
      "         327     0.5238    0.3143    0.3929        35\n",
      "         345     0.1373    0.2692    0.1818        26\n",
      "         347     0.2800    0.2917    0.2857        24\n",
      "         352     0.5028    0.7815    0.6119       453\n",
      "         362     0.4343    0.6230    0.5118       122\n",
      "         400     0.2317    0.5725    0.3299       138\n",
      "         401     0.3962    0.4038    0.4000        52\n",
      "         415     0.8387    0.6190    0.7123        42\n",
      "         416     0.6198    0.7723    0.6877       325\n",
      "         426     0.5862    0.4048    0.4789        42\n",
      "         427     0.4304    0.7727    0.5528        44\n",
      "         434     0.4497    0.8299    0.5833       194\n",
      "         476     0.6417    0.6906    0.6652       223\n",
      "         502     0.5564    0.6916    0.6167       107\n",
      "         522     0.4433    0.4778    0.4599        90\n",
      "         532     0.4638    0.7273    0.5664        44\n",
      "          59     0.7333    0.8073    0.7686       109\n",
      "         601     0.5106    0.6761    0.5818        71\n",
      "         611     0.5917    0.7717    0.6698        92\n",
      "         617     0.4884    0.5526    0.5185        38\n",
      "         639     0.2195    0.3214    0.2609        28\n",
      "         668     0.0968    0.0667    0.0789        45\n",
      "         732     0.2603    0.1939    0.2222        98\n",
      "          74     0.1783    0.3944    0.2456        71\n",
      "         755     0.1692    0.3929    0.2366        28\n",
      "          77     0.3039    0.5811    0.3991       148\n",
      "         770     0.2308    0.2542    0.2419        59\n",
      "         772     0.4250    0.5000    0.4595        34\n",
      "          78     0.5330    0.6554    0.5879       296\n",
      "         787     0.6804    0.5742    0.6228       890\n",
      "          79     0.9844    0.5603    0.7141      2256\n",
      "         798     0.7153    0.7984    0.7546       129\n",
      "         835     0.6078    0.7561    0.6739        41\n",
      "         843     0.5455    0.3529    0.4286        34\n",
      "         862     0.4983    0.6591    0.5675       220\n",
      "         863     0.2925    0.2627    0.2768       118\n",
      "          89     0.9780    0.7429    0.8444       957\n",
      "         908     0.5333    0.3333    0.4103        24\n",
      "         918     0.3278    0.6556    0.4370        90\n",
      "          94     0.2842    0.6473    0.3950       292\n",
      "\n",
      "    accuracy                         0.5857     12845\n",
      "   macro avg     0.4742    0.5354    0.4851     12845\n",
      "weighted avg     0.6765    0.5857    0.6028     12845\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['label_encoder_train.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import joblib\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class F1ScoreCallback(Callback):\n",
    "    def __init__(self, X_val, y_val):\n",
    "        super(F1ScoreCallback, self).__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.best_f1 = 0.0\n",
    "        self.best_model = None\n",
    "        self.f1_scores = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_val_pred = np.argmax(self.model.predict(self.X_val), axis=1)\n",
    "        f1 = f1_score(self.y_val, y_val_pred, average='weighted')\n",
    "        self.f1_scores.append(f1)\n",
    "        \n",
    "\n",
    "        if f1 > self.best_f1:\n",
    "            self.best_f1 = f1\n",
    "            self.best_model = self.model\n",
    "            print(f\"Epoch {epoch + 1} - F1 Score: {f1:.4f}\")\n",
    "            print(\"Saved best model\")\n",
    "            print(self.f1_scores)\n",
    "\n",
    "with open('train_repl_subj.pickle', 'rb') as f1:\n",
    "    balanced = pickle.load(f1)\n",
    "\n",
    "with open('test_repl_subj.pickle', 'rb') as f2:\n",
    "    unbalanced = pickle.load(f2)\n",
    "\n",
    "train = np.array([item['cve_description_replaced_subject_ada_embedding'] for item in balanced if item['cwe'] != 'None'])\n",
    "test = np.array([item['cwe'] for item in balanced if item['cwe'] != 'None'])\n",
    "np.random.seed(42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(train,test,test_size=0.1,random_state=42)\n",
    "\n",
    "X_test = np.array([item['cve_description_replaced_subject_ada_embedding'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "y_test = np.array([item['cwe'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "\n",
    "label_encoder_train = LabelEncoder()\n",
    "y_train_encoded = label_encoder_train.fit_transform(y_train)\n",
    "label_encoder_test = LabelEncoder()\n",
    "y_test_encoded = label_encoder_test.fit_transform(y_test)\n",
    "\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = len(np.unique(y_train))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "f1_callback = F1ScoreCallback(X_val, label_encoder_train.transform(y_val))\n",
    "\n",
    "history = model.fit(X_train, y_train_encoded, epochs=40, batch_size=32, validation_data=(X_val, label_encoder_train.transform(y_val)), verbose=1, callbacks=[f1_callback])\n",
    "\n",
    "best_model = f1_callback.best_model\n",
    "\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model, 'CWE_classes.joblib')\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_probs = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "y_pred_original = label_encoder_train.inverse_transform(y_pred)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_original, digits=4))\n",
    "\n",
    "joblib.dump(label_encoder_train, 'label_encoder_train.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference CVE description with replaced subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 [==============================] - 1s 2ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         119     0.8127    0.4785    0.6024      1070\n",
      "         120     0.3023    0.6633    0.4153       196\n",
      "         125     0.7864    0.7613    0.7736       532\n",
      "         134     0.4483    0.6842    0.5417        19\n",
      "         190     0.4710    0.6900    0.5598       200\n",
      "          20     0.4938    0.2963    0.3704       810\n",
      "         200     0.8011    0.4915    0.6092       590\n",
      "         203     0.6207    0.6667    0.6429        27\n",
      "          22     0.8489    0.7375    0.7893       518\n",
      "         269     0.2023    0.5000    0.2880       106\n",
      "         276     0.1600    0.1875    0.1727        64\n",
      "         287     0.4306    0.6316    0.5121       285\n",
      "         295     0.6500    0.6420    0.6460        81\n",
      "         306     0.3063    0.3617    0.3317        94\n",
      "         312     0.1818    0.2381    0.2062        42\n",
      "         319     0.4727    0.5098    0.4906        51\n",
      "         326     0.3182    0.2258    0.2642        31\n",
      "         327     0.5238    0.3143    0.3929        35\n",
      "         345     0.1373    0.2692    0.1818        26\n",
      "         347     0.2800    0.2917    0.2857        24\n",
      "         352     0.5028    0.7815    0.6119       453\n",
      "         362     0.4343    0.6230    0.5118       122\n",
      "         400     0.2317    0.5725    0.3299       138\n",
      "         401     0.3962    0.4038    0.4000        52\n",
      "         415     0.8387    0.6190    0.7123        42\n",
      "         416     0.6198    0.7723    0.6877       325\n",
      "         426     0.5862    0.4048    0.4789        42\n",
      "         427     0.4304    0.7727    0.5528        44\n",
      "         434     0.4497    0.8299    0.5833       194\n",
      "         476     0.6417    0.6906    0.6652       223\n",
      "         502     0.5564    0.6916    0.6167       107\n",
      "         522     0.4433    0.4778    0.4599        90\n",
      "         532     0.4638    0.7273    0.5664        44\n",
      "          59     0.7333    0.8073    0.7686       109\n",
      "         601     0.5106    0.6761    0.5818        71\n",
      "         611     0.5917    0.7717    0.6698        92\n",
      "         617     0.4884    0.5526    0.5185        38\n",
      "         639     0.2195    0.3214    0.2609        28\n",
      "         668     0.0968    0.0667    0.0789        45\n",
      "         732     0.2603    0.1939    0.2222        98\n",
      "          74     0.1783    0.3944    0.2456        71\n",
      "         755     0.1692    0.3929    0.2366        28\n",
      "          77     0.3039    0.5811    0.3991       148\n",
      "         770     0.2308    0.2542    0.2419        59\n",
      "         772     0.4250    0.5000    0.4595        34\n",
      "          78     0.5330    0.6554    0.5879       296\n",
      "         787     0.6804    0.5742    0.6228       890\n",
      "          79     0.9844    0.5603    0.7141      2256\n",
      "         798     0.7153    0.7984    0.7546       129\n",
      "         835     0.6078    0.7561    0.6739        41\n",
      "         843     0.5455    0.3529    0.4286        34\n",
      "         862     0.4983    0.6591    0.5675       220\n",
      "         863     0.2925    0.2627    0.2768       118\n",
      "          89     0.9780    0.7429    0.8444       957\n",
      "         908     0.5333    0.3333    0.4103        24\n",
      "         918     0.3278    0.6556    0.4370        90\n",
      "          94     0.2842    0.6473    0.3950       292\n",
      "\n",
      "    accuracy                         0.5857     12845\n",
      "   macro avg     0.4742    0.5354    0.4851     12845\n",
      "weighted avg     0.6765    0.5857    0.6028     12845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# Load the saved model\n",
    "best_model = joblib.load('CWE_classes.joblib')\n",
    "\n",
    "# Load the label encoder\n",
    "label_encoder_train = joblib.load('label_encoder_train.joblib')\n",
    "\n",
    "# Load the test data\n",
    "with open('test_repl_subj.pickle', 'rb') as f2:\n",
    "    unbalanced = pickle.load(f2)\n",
    "\n",
    "X_test = np.array([item['cve_description_replaced_subject_ada_embedding'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "y_test = np.array([item['cwe'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_probs = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Convert the predicted labels back to their original form\n",
    "y_pred_original = label_encoder_train.inverse_transform(y_pred)\n",
    "\n",
    "# Generate and print the classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_original, digits=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train based on CVE terms with Phi-2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "227/227 [==============================] - 1s 2ms/step loss: 2.1685\n",
      "Epoch 1 - F1 Score: 0.5195\n",
      "Saved best model\n",
      "[0.5194653477557486]\n",
      "2036/2036 [==============================] - 19s 9ms/step - loss: 2.1681 - accuracy: 0.4229 - val_loss: 1.6272 - val_accuracy: 0.5515\n",
      "Epoch 2/40\n",
      "227/227 [==============================] - 1s 4ms/step\n",
      "Epoch 2 - F1 Score: 0.5555\n",
      "Saved best model\n",
      "[0.5194653477557486, 0.555486880994522]\n",
      "2036/2036 [==============================] - 18s 9ms/step - loss: 1.5773 - accuracy: 0.5642 - val_loss: 1.5381 - val_accuracy: 0.5773\n",
      "Epoch 3/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.4477 \n",
      "Epoch 3 - F1 Score: 0.5916\n",
      "Saved best model\n",
      "[0.5194653477557486, 0.555486880994522, 0.5916274211500077]\n",
      "2036/2036 [==============================] - 20s 10ms/step - loss: 1.4476 - accuracy: 0.5971 - val_loss: 1.3689 - val_accuracy: 0.6168\n",
      "Epoch 4/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.3812 - \n",
      "2036/2036 [==============================] - 20s 10ms/step - loss: 1.3812 - accuracy: 0.6120 - val_loss: 1.5407 - val_accuracy: 0.5878\n",
      "Epoch 5/40\n",
      "227/227 [==============================] - 1s 3ms/step loss:\n",
      "2036/2036 [==============================] - 19s 9ms/step - loss: 1.3302 - accuracy: 0.6240 - val_loss: 1.3828 - val_accuracy: 0.6078\n",
      "Epoch 6/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.3006 - \n",
      "Epoch 6 - F1 Score: 0.6193\n",
      "Saved best model\n",
      "[0.5194653477557486, 0.555486880994522, 0.5916274211500077, 0.5703611451313957, 0.5873786773630832, 0.6192570572984668]\n",
      "2036/2036 [==============================] - 16s 8ms/step - loss: 1.3006 - accuracy: 0.6314 - val_loss: 1.2774 - val_accuracy: 0.6405\n",
      "Epoch 7/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.2690 \n",
      "Epoch 7 - F1 Score: 0.6295\n",
      "Saved best model\n",
      "[0.5194653477557486, 0.555486880994522, 0.5916274211500077, 0.5703611451313957, 0.5873786773630832, 0.6192570572984668, 0.6295347264863698]\n",
      "2036/2036 [==============================] - 14s 7ms/step - loss: 1.2690 - accuracy: 0.6426 - val_loss: 1.2937 - val_accuracy: 0.6443\n",
      "Epoch 8/40\n",
      "227/227 [==============================] - 1s 3ms/step loss:\n",
      "2036/2036 [==============================] - 20s 10ms/step - loss: 1.2507 - accuracy: 0.6451 - val_loss: 1.2573 - val_accuracy: 0.6400\n",
      "Epoch 9/40\n",
      "227/227 [==============================] - 1s 3ms/step loss: 1\n",
      "Epoch 9 - F1 Score: 0.6395\n",
      "Saved best model\n",
      "[0.5194653477557486, 0.555486880994522, 0.5916274211500077, 0.5703611451313957, 0.5873786773630832, 0.6192570572984668, 0.6295347264863698, 0.6239142516700469, 0.639475934761174]\n",
      "2036/2036 [==============================] - 20s 10ms/step - loss: 1.2309 - accuracy: 0.6511 - val_loss: 1.2236 - val_accuracy: 0.6591\n",
      "Epoch 10/40\n",
      "227/227 [==============================] - 1s 3ms/step los\n",
      "Epoch 10 - F1 Score: 0.6425\n",
      "Saved best model\n",
      "[0.5194653477557486, 0.555486880994522, 0.5916274211500077, 0.5703611451313957, 0.5873786773630832, 0.6192570572984668, 0.6295347264863698, 0.6239142516700469, 0.639475934761174, 0.642479697714748]\n",
      "2036/2036 [==============================] - 19s 10ms/step - loss: 1.2173 - accuracy: 0.6539 - val_loss: 1.2050 - val_accuracy: 0.6641\n",
      "Epoch 11/40\n",
      "227/227 [==============================] - 1s 2ms/step loss: 1.205\n",
      "2036/2036 [==============================] - 20s 10ms/step - loss: 1.2049 - accuracy: 0.6560 - val_loss: 1.2924 - val_accuracy: 0.6420\n",
      "Epoch 12/40\n",
      "227/227 [==============================] - 1s 4ms/step\n",
      "Epoch 12 - F1 Score: 0.6483\n",
      "Saved best model\n",
      "[0.5194653477557486, 0.555486880994522, 0.5916274211500077, 0.5703611451313957, 0.5873786773630832, 0.6192570572984668, 0.6295347264863698, 0.6239142516700469, 0.639475934761174, 0.642479697714748, 0.620196475500133, 0.6482619024683178]\n",
      "2036/2036 [==============================] - 19s 10ms/step - loss: 1.1946 - accuracy: 0.6601 - val_loss: 1.1983 - val_accuracy: 0.6646\n",
      "Epoch 13/40\n",
      "227/227 [==============================] - 1s 3ms/step loss:\n",
      "Epoch 13 - F1 Score: 0.6562\n",
      "Saved best model\n",
      "[0.5194653477557486, 0.555486880994522, 0.5916274211500077, 0.5703611451313957, 0.5873786773630832, 0.6192570572984668, 0.6295347264863698, 0.6239142516700469, 0.639475934761174, 0.642479697714748, 0.620196475500133, 0.6482619024683178, 0.6562401097539425]\n",
      "2036/2036 [==============================] - 19s 10ms/step - loss: 1.1816 - accuracy: 0.6628 - val_loss: 1.2052 - val_accuracy: 0.6715\n",
      "Epoch 14/40\n",
      "227/227 [==============================] - 1s 2ms/step loss: 1.1\n",
      "2036/2036 [==============================] - 19s 9ms/step - loss: 1.1714 - accuracy: 0.6651 - val_loss: 1.2074 - val_accuracy: 0.6653\n",
      "Epoch 15/40\n",
      "227/227 [==============================] - 1s 3ms/step loss:\n",
      "2036/2036 [==============================] - 18s 9ms/step - loss: 1.1600 - accuracy: 0.6684 - val_loss: 1.2590 - val_accuracy: 0.6548\n",
      "Epoch 16/40\n",
      "227/227 [==============================] - 1s 3ms/step loss: 1\n",
      "2036/2036 [==============================] - 19s 9ms/step - loss: 1.1497 - accuracy: 0.6713 - val_loss: 1.2358 - val_accuracy: 0.6555\n",
      "Epoch 17/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.1442 - \n",
      "2036/2036 [==============================] - 15s 8ms/step - loss: 1.1442 - accuracy: 0.6726 - val_loss: 1.2643 - val_accuracy: 0.6568\n",
      "Epoch 18/40\n",
      "227/227 [==============================] - 1s 3ms/step loss: 1\n",
      "2036/2036 [==============================] - 20s 10ms/step - loss: 1.1366 - accuracy: 0.6751 - val_loss: 1.1906 - val_accuracy: 0.6659\n",
      "Epoch 19/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.1284 - ac\n",
      "2036/2036 [==============================] - 19s 9ms/step - loss: 1.1285 - accuracy: 0.6767 - val_loss: 1.2091 - val_accuracy: 0.6651\n",
      "Epoch 20/40\n",
      "227/227 [==============================] - 1s 3ms/step l\n",
      "Epoch 20 - F1 Score: 0.6614\n",
      "Saved best model\n",
      "[0.5194653477557486, 0.555486880994522, 0.5916274211500077, 0.5703611451313957, 0.5873786773630832, 0.6192570572984668, 0.6295347264863698, 0.6239142516700469, 0.639475934761174, 0.642479697714748, 0.620196475500133, 0.6482619024683178, 0.6562401097539425, 0.6487243267064502, 0.6447952781233426, 0.6424133412779913, 0.6402601545833563, 0.6490477558178808, 0.6482315809059951, 0.6613831578695577]\n",
      "2036/2036 [==============================] - 20s 10ms/step - loss: 1.1200 - accuracy: 0.6785 - val_loss: 1.1968 - val_accuracy: 0.6681\n",
      "Epoch 21/40\n",
      "227/227 [==============================] - 1s 3ms/step l\n",
      "2036/2036 [==============================] - 19s 9ms/step - loss: 1.1159 - accuracy: 0.6781 - val_loss: 1.1993 - val_accuracy: 0.6714\n",
      "Epoch 22/40\n",
      "227/227 [==============================] - 1s 3ms/step loss:\n",
      "2036/2036 [==============================] - 20s 10ms/step - loss: 1.1065 - accuracy: 0.6817 - val_loss: 1.1843 - val_accuracy: 0.6685\n",
      "Epoch 23/40\n",
      "227/227 [==============================] - 1s 3ms/step loss: 1\n",
      "Epoch 23 - F1 Score: 0.6614\n",
      "Saved best model\n",
      "[0.5194653477557486, 0.555486880994522, 0.5916274211500077, 0.5703611451313957, 0.5873786773630832, 0.6192570572984668, 0.6295347264863698, 0.6239142516700469, 0.639475934761174, 0.642479697714748, 0.620196475500133, 0.6482619024683178, 0.6562401097539425, 0.6487243267064502, 0.6447952781233426, 0.6424133412779913, 0.6402601545833563, 0.6490477558178808, 0.6482315809059951, 0.6613831578695577, 0.6533452473259304, 0.6600200961045569, 0.6614178836361294]\n",
      "2036/2036 [==============================] - 19s 9ms/step - loss: 1.1035 - accuracy: 0.6826 - val_loss: 1.1788 - val_accuracy: 0.6713\n",
      "Epoch 24/40\n",
      "227/227 [==============================] - 1s 2ms/step loss: 1.0\n",
      "Epoch 24 - F1 Score: 0.6674\n",
      "Saved best model\n",
      "[0.5194653477557486, 0.555486880994522, 0.5916274211500077, 0.5703611451313957, 0.5873786773630832, 0.6192570572984668, 0.6295347264863698, 0.6239142516700469, 0.639475934761174, 0.642479697714748, 0.620196475500133, 0.6482619024683178, 0.6562401097539425, 0.6487243267064502, 0.6447952781233426, 0.6424133412779913, 0.6402601545833563, 0.6490477558178808, 0.6482315809059951, 0.6613831578695577, 0.6533452473259304, 0.6600200961045569, 0.6614178836361294, 0.6674005932036416]\n",
      "2036/2036 [==============================] - 18s 9ms/step - loss: 1.0973 - accuracy: 0.6838 - val_loss: 1.1345 - val_accuracy: 0.6815\n",
      "Epoch 25/40\n",
      "227/227 [==============================] - 1s 3ms/step loss: 1\n",
      "2036/2036 [==============================] - 19s 9ms/step - loss: 1.1010 - accuracy: 0.6827 - val_loss: 1.1935 - val_accuracy: 0.6695\n",
      "Epoch 26/40\n",
      "227/227 [==============================] - 1s 3ms/step loss:\n",
      "2036/2036 [==============================] - 16s 8ms/step - loss: 1.0928 - accuracy: 0.6839 - val_loss: 1.1974 - val_accuracy: 0.6693\n",
      "Epoch 27/40\n",
      "227/227 [==============================] - 1s 3ms/step loss:\n",
      "Epoch 27 - F1 Score: 0.6705\n",
      "Saved best model\n",
      "[0.5194653477557486, 0.555486880994522, 0.5916274211500077, 0.5703611451313957, 0.5873786773630832, 0.6192570572984668, 0.6295347264863698, 0.6239142516700469, 0.639475934761174, 0.642479697714748, 0.620196475500133, 0.6482619024683178, 0.6562401097539425, 0.6487243267064502, 0.6447952781233426, 0.6424133412779913, 0.6402601545833563, 0.6490477558178808, 0.6482315809059951, 0.6613831578695577, 0.6533452473259304, 0.6600200961045569, 0.6614178836361294, 0.6674005932036416, 0.6588859224540791, 0.6630467326574908, 0.6704943839508798]\n",
      "2036/2036 [==============================] - 16s 8ms/step - loss: 1.0846 - accuracy: 0.6870 - val_loss: 1.1600 - val_accuracy: 0.6797\n",
      "Epoch 28/40\n",
      "227/227 [==============================] - 1s 3ms/step l\n",
      "2036/2036 [==============================] - 15s 7ms/step - loss: 1.0805 - accuracy: 0.6876 - val_loss: 1.2105 - val_accuracy: 0.6613\n",
      "Epoch 29/40\n",
      "227/227 [==============================] - 1s 4ms/step\n",
      "2036/2036 [==============================] - 19s 9ms/step - loss: 1.0762 - accuracy: 0.6897 - val_loss: 1.2006 - val_accuracy: 0.6651\n",
      "Epoch 30/40\n",
      "227/227 [==============================] - 1s 3ms/step loss:\n",
      "2036/2036 [==============================] - 20s 10ms/step - loss: 1.0689 - accuracy: 0.6902 - val_loss: 1.2127 - val_accuracy: 0.6698\n",
      "Epoch 31/40\n",
      "227/227 [==============================] - 1s 3ms/step l\n",
      "2036/2036 [==============================] - 19s 9ms/step - loss: 1.0711 - accuracy: 0.6910 - val_loss: 1.2121 - val_accuracy: 0.6630\n",
      "Epoch 32/40\n",
      "227/227 [==============================] - 1s 3ms/step loss: 1\n",
      "2036/2036 [==============================] - 18s 9ms/step - loss: 1.0623 - accuracy: 0.6924 - val_loss: 1.1635 - val_accuracy: 0.6786\n",
      "Epoch 33/40\n",
      "227/227 [==============================] - 1s 3ms/step los\n",
      "2036/2036 [==============================] - 17s 8ms/step - loss: 1.0551 - accuracy: 0.6947 - val_loss: 1.1393 - val_accuracy: 0.6796\n",
      "Epoch 34/40\n",
      "227/227 [==============================] - 1s 3ms/step l\n",
      "2036/2036 [==============================] - 17s 8ms/step - loss: 1.0563 - accuracy: 0.6945 - val_loss: 1.2036 - val_accuracy: 0.6655\n",
      "Epoch 35/40\n",
      "227/227 [==============================] - 1s 3ms/step loss:\n",
      "Epoch 35 - F1 Score: 0.6722\n",
      "Saved best model\n",
      "[0.5194653477557486, 0.555486880994522, 0.5916274211500077, 0.5703611451313957, 0.5873786773630832, 0.6192570572984668, 0.6295347264863698, 0.6239142516700469, 0.639475934761174, 0.642479697714748, 0.620196475500133, 0.6482619024683178, 0.6562401097539425, 0.6487243267064502, 0.6447952781233426, 0.6424133412779913, 0.6402601545833563, 0.6490477558178808, 0.6482315809059951, 0.6613831578695577, 0.6533452473259304, 0.6600200961045569, 0.6614178836361294, 0.6674005932036416, 0.6588859224540791, 0.6630467326574908, 0.6704943839508798, 0.6538212432067766, 0.6512501567267514, 0.6599766080044365, 0.6559259926028898, 0.670024862865687, 0.668064473980602, 0.6559451873409898, 0.6721976455401842]\n",
      "2036/2036 [==============================] - 18s 9ms/step - loss: 1.0541 - accuracy: 0.6950 - val_loss: 1.1496 - val_accuracy: 0.6833\n",
      "Epoch 36/40\n",
      "227/227 [==============================] - 1s 3ms/step los\n",
      "2036/2036 [==============================] - 16s 8ms/step - loss: 1.0481 - accuracy: 0.6961 - val_loss: 1.1812 - val_accuracy: 0.6785\n",
      "Epoch 37/40\n",
      "227/227 [==============================] - 1s 2ms/step loss: 1.0\n",
      "2036/2036 [==============================] - 16s 8ms/step - loss: 1.0499 - accuracy: 0.6950 - val_loss: 1.2506 - val_accuracy: 0.6635\n",
      "Epoch 38/40\n",
      "227/227 [==============================] - 1s 3ms/step los\n",
      "2036/2036 [==============================] - 20s 10ms/step - loss: 1.0443 - accuracy: 0.6976 - val_loss: 1.2664 - val_accuracy: 0.6594\n",
      "Epoch 39/40\n",
      "227/227 [==============================] - 1s 3ms/step loss:\n",
      "Epoch 39 - F1 Score: 0.6806\n",
      "Saved best model\n",
      "[0.5194653477557486, 0.555486880994522, 0.5916274211500077, 0.5703611451313957, 0.5873786773630832, 0.6192570572984668, 0.6295347264863698, 0.6239142516700469, 0.639475934761174, 0.642479697714748, 0.620196475500133, 0.6482619024683178, 0.6562401097539425, 0.6487243267064502, 0.6447952781233426, 0.6424133412779913, 0.6402601545833563, 0.6490477558178808, 0.6482315809059951, 0.6613831578695577, 0.6533452473259304, 0.6600200961045569, 0.6614178836361294, 0.6674005932036416, 0.6588859224540791, 0.6630467326574908, 0.6704943839508798, 0.6538212432067766, 0.6512501567267514, 0.6599766080044365, 0.6559259926028898, 0.670024862865687, 0.668064473980602, 0.6559451873409898, 0.6721976455401842, 0.6639978136029832, 0.6608982495562182, 0.6478267506811346, 0.6806020852602463]\n",
      "2036/2036 [==============================] - 19s 9ms/step - loss: 1.0411 - accuracy: 0.6975 - val_loss: 1.1100 - val_accuracy: 0.6943\n",
      "Epoch 40/40\n",
      "227/227 [==============================] - 1s 2ms/step loss: 1.0\n",
      "2036/2036 [==============================] - 20s 10ms/step - loss: 1.0393 - accuracy: 0.6987 - val_loss: 1.1725 - val_accuracy: 0.6754\n",
      "402/402 [==============================] - 1s 4ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         119     0.7793    0.5477    0.6432      1070\n",
      "         120     0.3464    0.6786    0.4586       196\n",
      "         125     0.7542    0.7669    0.7605       532\n",
      "         134     0.6154    0.8421    0.7111        19\n",
      "         190     0.8333    0.8000    0.8163       200\n",
      "          20     0.4380    0.3753    0.4043       810\n",
      "         200     0.6949    0.5288    0.6006       590\n",
      "         203     0.6000    0.5556    0.5769        27\n",
      "          22     0.8457    0.8996    0.8718       518\n",
      "         269     0.3333    0.4623    0.3874       106\n",
      "         276     0.2500    0.2656    0.2576        64\n",
      "         287     0.4183    0.7368    0.5337       285\n",
      "         295     0.6190    0.6420    0.6303        81\n",
      "         306     0.2979    0.1489    0.1986        94\n",
      "         312     0.3846    0.1190    0.1818        42\n",
      "         319     0.5161    0.3137    0.3902        51\n",
      "         326     0.2000    0.1613    0.1786        31\n",
      "         327     0.3404    0.4571    0.3902        35\n",
      "         345     0.4444    0.1538    0.2286        26\n",
      "         347     0.4000    0.2500    0.3077        24\n",
      "         352     0.5961    0.9448    0.7310       453\n",
      "         362     0.7979    0.6148    0.6944       122\n",
      "         400     0.3696    0.3696    0.3696       138\n",
      "         401     0.5000    0.3846    0.4348        52\n",
      "         415     0.7755    0.9048    0.8352        42\n",
      "         416     0.7871    0.8646    0.8240       325\n",
      "         426     0.5319    0.5952    0.5618        42\n",
      "         427     0.4079    0.7045    0.5167        44\n",
      "         434     0.6830    0.7887    0.7321       194\n",
      "         476     0.6199    0.8117    0.7029       223\n",
      "         502     0.6635    0.6449    0.6540       107\n",
      "         522     0.4634    0.4222    0.4419        90\n",
      "         532     0.4348    0.4545    0.4444        44\n",
      "          59     0.7308    0.6972    0.7136       109\n",
      "         601     0.3554    0.8310    0.4979        71\n",
      "         611     0.7094    0.9022    0.7943        92\n",
      "         617     0.7727    0.4474    0.5667        38\n",
      "         639     0.7692    0.3571    0.4878        28\n",
      "         668     0.1429    0.0222    0.0385        45\n",
      "         732     0.2206    0.1531    0.1807        98\n",
      "          74     0.0596    0.1268    0.0811        71\n",
      "         755     0.2609    0.2143    0.2353        28\n",
      "          77     0.6575    0.3243    0.4344       148\n",
      "         770     0.3636    0.3390    0.3509        59\n",
      "         772     0.4722    0.5000    0.4857        34\n",
      "          78     0.5644    0.7703    0.6514       296\n",
      "         787     0.6238    0.7472    0.6800       890\n",
      "          79     0.9820    0.7500    0.8505      2256\n",
      "         798     0.7615    0.7674    0.7645       129\n",
      "         835     0.4615    0.5854    0.5161        41\n",
      "         843     0.7188    0.6765    0.6970        34\n",
      "         862     0.6614    0.5682    0.6112       220\n",
      "         863     0.2857    0.1186    0.1677       118\n",
      "          89     0.9928    0.8673    0.9258       957\n",
      "         908     0.9091    0.4167    0.5714        24\n",
      "         918     0.5423    0.8556    0.6638        90\n",
      "          94     0.3866    0.6712    0.4906       292\n",
      "\n",
      "    accuracy                         0.6655     12845\n",
      "   macro avg     0.5464    0.5424    0.5250     12845\n",
      "weighted avg     0.7002    0.6655    0.6685     12845\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['label_encoder_train_terms.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import joblib\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class F1ScoreCallback(Callback):\n",
    "    def __init__(self, X_val, y_val):\n",
    "        super(F1ScoreCallback, self).__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.best_f1 = 0.0\n",
    "        self.best_model = None\n",
    "        self.f1_scores = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_val_pred = np.argmax(self.model.predict(self.X_val), axis=1)\n",
    "        f1 = f1_score(self.y_val, y_val_pred, average='weighted')\n",
    "        self.f1_scores.append(f1)\n",
    "        \n",
    "\n",
    "        if f1 > self.best_f1:\n",
    "            self.best_f1 = f1\n",
    "            self.best_model = self.model\n",
    "            print(f\"Epoch {epoch + 1} - F1 Score: {f1:.4f}\")\n",
    "            print(\"Saved best model\")\n",
    "            print(self.f1_scores)\n",
    "\n",
    "with open('train_phi_comp.pickle', 'rb') as f1:\n",
    "    balanced = pickle.load(f1)\n",
    "\n",
    "with open('phi_terms_comp_test.pickle', 'rb') as f2:\n",
    "    unbalanced = pickle.load(f2)\n",
    "\n",
    "train = np.array([item['cve_terms_phi'] for item in balanced if item['cwe'] != 'None'])\n",
    "test = np.array([item['cwe'] for item in balanced if item['cwe'] != 'None'])\n",
    "np.random.seed(42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(train,test,test_size=0.1,random_state=42)\n",
    "\n",
    "X_test = np.array([item['cve_terms_phi'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "y_test = np.array([item['cwe'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "\n",
    "label_encoder_train = LabelEncoder()\n",
    "y_train_encoded = label_encoder_train.fit_transform(y_train)\n",
    "label_encoder_test = LabelEncoder()\n",
    "y_test_encoded = label_encoder_test.fit_transform(y_test)\n",
    "\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = len(np.unique(y_train))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "f1_callback = F1ScoreCallback(X_val, label_encoder_train.transform(y_val))\n",
    "\n",
    "history = model.fit(X_train, y_train_encoded, epochs=40, batch_size=32, validation_data=(X_val, label_encoder_train.transform(y_val)), verbose=1, callbacks=[f1_callback])\n",
    "\n",
    "best_model = f1_callback.best_model\n",
    "\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model, 'best_model_terms.joblib')\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_probs = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "y_pred_original = label_encoder_train.inverse_transform(y_pred)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_original, digits=4))\n",
    "\n",
    "joblib.dump(label_encoder_train, 'label_encoder_train_terms.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference CVE terms with Phi-2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 [==============================] - 1s 2ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         119     0.7793    0.5477    0.6432      1070\n",
      "         120     0.3464    0.6786    0.4586       196\n",
      "         125     0.7542    0.7669    0.7605       532\n",
      "         134     0.6154    0.8421    0.7111        19\n",
      "         190     0.8333    0.8000    0.8163       200\n",
      "          20     0.4380    0.3753    0.4043       810\n",
      "         200     0.6949    0.5288    0.6006       590\n",
      "         203     0.6000    0.5556    0.5769        27\n",
      "          22     0.8457    0.8996    0.8718       518\n",
      "         269     0.3333    0.4623    0.3874       106\n",
      "         276     0.2500    0.2656    0.2576        64\n",
      "         287     0.4183    0.7368    0.5337       285\n",
      "         295     0.6190    0.6420    0.6303        81\n",
      "         306     0.2979    0.1489    0.1986        94\n",
      "         312     0.3846    0.1190    0.1818        42\n",
      "         319     0.5161    0.3137    0.3902        51\n",
      "         326     0.2000    0.1613    0.1786        31\n",
      "         327     0.3404    0.4571    0.3902        35\n",
      "         345     0.4444    0.1538    0.2286        26\n",
      "         347     0.4000    0.2500    0.3077        24\n",
      "         352     0.5961    0.9448    0.7310       453\n",
      "         362     0.7979    0.6148    0.6944       122\n",
      "         400     0.3696    0.3696    0.3696       138\n",
      "         401     0.5000    0.3846    0.4348        52\n",
      "         415     0.7755    0.9048    0.8352        42\n",
      "         416     0.7871    0.8646    0.8240       325\n",
      "         426     0.5319    0.5952    0.5618        42\n",
      "         427     0.4079    0.7045    0.5167        44\n",
      "         434     0.6830    0.7887    0.7321       194\n",
      "         476     0.6199    0.8117    0.7029       223\n",
      "         502     0.6635    0.6449    0.6540       107\n",
      "         522     0.4634    0.4222    0.4419        90\n",
      "         532     0.4348    0.4545    0.4444        44\n",
      "          59     0.7308    0.6972    0.7136       109\n",
      "         601     0.3554    0.8310    0.4979        71\n",
      "         611     0.7094    0.9022    0.7943        92\n",
      "         617     0.7727    0.4474    0.5667        38\n",
      "         639     0.7692    0.3571    0.4878        28\n",
      "         668     0.1429    0.0222    0.0385        45\n",
      "         732     0.2206    0.1531    0.1807        98\n",
      "          74     0.0596    0.1268    0.0811        71\n",
      "         755     0.2609    0.2143    0.2353        28\n",
      "          77     0.6575    0.3243    0.4344       148\n",
      "         770     0.3636    0.3390    0.3509        59\n",
      "         772     0.4722    0.5000    0.4857        34\n",
      "          78     0.5644    0.7703    0.6514       296\n",
      "         787     0.6238    0.7472    0.6800       890\n",
      "          79     0.9820    0.7500    0.8505      2256\n",
      "         798     0.7615    0.7674    0.7645       129\n",
      "         835     0.4615    0.5854    0.5161        41\n",
      "         843     0.7188    0.6765    0.6970        34\n",
      "         862     0.6614    0.5682    0.6112       220\n",
      "         863     0.2857    0.1186    0.1677       118\n",
      "          89     0.9928    0.8673    0.9258       957\n",
      "         908     0.9091    0.4167    0.5714        24\n",
      "         918     0.5423    0.8556    0.6638        90\n",
      "          94     0.3866    0.6712    0.4906       292\n",
      "\n",
      "    accuracy                         0.6655     12845\n",
      "   macro avg     0.5464    0.5424    0.5250     12845\n",
      "weighted avg     0.7002    0.6655    0.6685     12845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Save the best model\n",
    "with open('phi_terms_comp_test.pickle', 'rb') as f2:\n",
    "    unbalanced = pickle.load(f2)\n",
    "\n",
    "X_test = np.array([item['cve_terms_phi'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "y_test = np.array([item['cwe'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "\n",
    "best_model=joblib.load('best_model_terms.joblib')\n",
    "label_encoder_train=joblib.load('label_encoder_train_terms.joblib')\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_probs = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "y_pred_original = label_encoder_train.inverse_transform(y_pred)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_original, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train based on CVE descriptions with Phi-2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.9870 - accur\n",
      "Epoch 1 - F1 Score: 0.5419\n",
      "Saved best model\n",
      "[0.5418684902723947]\n",
      "2036/2036 [==============================] - 13s 6ms/step - loss: 1.9870 - accuracy: 0.4677 - val_loss: 1.5536 - val_accuracy: 0.5674\n",
      "Epoch 2/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.4207 - ac\n",
      "Epoch 2 - F1 Score: 0.5774\n",
      "Saved best model\n",
      "[0.5418684902723947, 0.5773995173326363]\n",
      "2036/2036 [==============================] - 11s 5ms/step - loss: 1.4210 - accuracy: 0.6007 - val_loss: 1.4522 - val_accuracy: 0.5916\n",
      "Epoch 3/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.2812 - ac\n",
      "Epoch 3 - F1 Score: 0.5990\n",
      "Saved best model\n",
      "[0.5418684902723947, 0.5773995173326363, 0.5990375093601406]\n",
      "2036/2036 [==============================] - 11s 5ms/step - loss: 1.2812 - accuracy: 0.6357 - val_loss: 1.3599 - val_accuracy: 0.6196\n",
      "Epoch 4/40\n",
      "227/227 [==============================] - 1s 3ms/step loss: 1\n",
      "Epoch 4 - F1 Score: 0.6228\n",
      "Saved best model\n",
      "[0.5418684902723947, 0.5773995173326363, 0.5990375093601406, 0.6228266641472865]\n",
      "2036/2036 [==============================] - 14s 7ms/step - loss: 1.1964 - accuracy: 0.6582 - val_loss: 1.2953 - val_accuracy: 0.6400\n",
      "Epoch 5/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.1333 - \n",
      "Epoch 5 - F1 Score: 0.6349\n",
      "Saved best model\n",
      "[0.5418684902723947, 0.5773995173326363, 0.5990375093601406, 0.6228266641472865, 0.6348700823131541]\n",
      "2036/2036 [==============================] - 13s 6ms/step - loss: 1.1330 - accuracy: 0.6730 - val_loss: 1.3225 - val_accuracy: 0.6416\n",
      "Epoch 6/40\n",
      "227/227 [==============================] - 1s 2ms/step loss: 1.0\n",
      "2036/2036 [==============================] - 19s 9ms/step - loss: 1.0913 - accuracy: 0.6827 - val_loss: 1.2869 - val_accuracy: 0.6458\n",
      "Epoch 7/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.0530 - \n",
      "2036/2036 [==============================] - 18s 9ms/step - loss: 1.0536 - accuracy: 0.6912 - val_loss: 1.3098 - val_accuracy: 0.6427\n",
      "Epoch 8/40\n",
      "227/227 [==============================] - 1s 3ms/step loss: 1\n",
      "Epoch 8 - F1 Score: 0.6497\n",
      "Saved best model\n",
      "[0.5418684902723947, 0.5773995173326363, 0.5990375093601406, 0.6228266641472865, 0.6348700823131541, 0.6315542857791329, 0.624950752853186, 0.6496610214955467]\n",
      "2036/2036 [==============================] - 20s 10ms/step - loss: 1.0207 - accuracy: 0.7013 - val_loss: 1.2756 - val_accuracy: 0.6578\n",
      "Epoch 9/40\n",
      "227/227 [==============================] - 1s 3ms/step loss: 0.\n",
      "2036/2036 [==============================] - 18s 9ms/step - loss: 0.9861 - accuracy: 0.7099 - val_loss: 1.2699 - val_accuracy: 0.6569\n",
      "Epoch 10/40\n",
      "227/227 [==============================] - 1s 3ms/step los\n",
      "2036/2036 [==============================] - 18s 9ms/step - loss: 0.9621 - accuracy: 0.7164 - val_loss: 1.3086 - val_accuracy: 0.6553\n",
      "Epoch 11/40\n",
      "227/227 [==============================] - 1s 4ms/step\n",
      "Epoch 11 - F1 Score: 0.6542\n",
      "Saved best model\n",
      "[0.5418684902723947, 0.5773995173326363, 0.5990375093601406, 0.6228266641472865, 0.6348700823131541, 0.6315542857791329, 0.624950752853186, 0.6496610214955467, 0.647572024492675, 0.6415453871385582, 0.6542437823237546]\n",
      "2036/2036 [==============================] - 20s 10ms/step - loss: 0.9406 - accuracy: 0.7222 - val_loss: 1.3027 - val_accuracy: 0.6604\n",
      "Epoch 12/40\n",
      "227/227 [==============================] - 1s 3ms/step loss: 0\n",
      "2036/2036 [==============================] - 20s 10ms/step - loss: 0.9166 - accuracy: 0.7259 - val_loss: 1.3325 - val_accuracy: 0.6571\n",
      "Epoch 13/40\n",
      "227/227 [==============================] - 1s 2ms/step loss: 0.8\n",
      "Epoch 13 - F1 Score: 0.6550\n",
      "Saved best model\n",
      "[0.5418684902723947, 0.5773995173326363, 0.5990375093601406, 0.6228266641472865, 0.6348700823131541, 0.6315542857791329, 0.624950752853186, 0.6496610214955467, 0.647572024492675, 0.6415453871385582, 0.6542437823237546, 0.6519015581660605, 0.6550412096734055]\n",
      "2036/2036 [==============================] - 19s 9ms/step - loss: 0.8994 - accuracy: 0.7299 - val_loss: 1.2882 - val_accuracy: 0.6661\n",
      "Epoch 14/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 0.8825 - \n",
      "Epoch 14 - F1 Score: 0.6603\n",
      "Saved best model\n",
      "[0.5418684902723947, 0.5773995173326363, 0.5990375093601406, 0.6228266641472865, 0.6348700823131541, 0.6315542857791329, 0.624950752853186, 0.6496610214955467, 0.647572024492675, 0.6415453871385582, 0.6542437823237546, 0.6519015581660605, 0.6550412096734055, 0.6602870862159756]\n",
      "2036/2036 [==============================] - 17s 8ms/step - loss: 0.8825 - accuracy: 0.7357 - val_loss: 1.2958 - val_accuracy: 0.6616\n",
      "Epoch 15/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 0.8649 - ac\n",
      "2036/2036 [==============================] - 15s 8ms/step - loss: 0.8651 - accuracy: 0.7403 - val_loss: 1.3610 - val_accuracy: 0.6549\n",
      "Epoch 16/40\n",
      "227/227 [==============================] - 1s 2ms/step loss: 0.8\n",
      "2036/2036 [==============================] - 16s 8ms/step - loss: 0.8472 - accuracy: 0.7445 - val_loss: 1.3666 - val_accuracy: 0.6565\n",
      "Epoch 17/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 0.8345 \n",
      "2036/2036 [==============================] - 17s 8ms/step - loss: 0.8345 - accuracy: 0.7481 - val_loss: 1.3621 - val_accuracy: 0.6587\n",
      "Epoch 18/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 0.8218 - ac\n",
      "Epoch 18 - F1 Score: 0.6625\n",
      "Saved best model\n",
      "[0.5418684902723947, 0.5773995173326363, 0.5990375093601406, 0.6228266641472865, 0.6348700823131541, 0.6315542857791329, 0.624950752853186, 0.6496610214955467, 0.647572024492675, 0.6415453871385582, 0.6542437823237546, 0.6519015581660605, 0.6550412096734055, 0.6602870862159756, 0.6471994682949284, 0.6439878957317533, 0.6516646039072213, 0.6625456125860082]\n",
      "2036/2036 [==============================] - 17s 8ms/step - loss: 0.8221 - accuracy: 0.7499 - val_loss: 1.3262 - val_accuracy: 0.6650\n",
      "Epoch 19/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 0.8096 - ac\n",
      "2036/2036 [==============================] - 17s 9ms/step - loss: 0.8095 - accuracy: 0.7541 - val_loss: 1.3623 - val_accuracy: 0.6565\n",
      "Epoch 20/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 0.7953 \n",
      "2036/2036 [==============================] - 17s 8ms/step - loss: 0.7953 - accuracy: 0.7561 - val_loss: 1.3658 - val_accuracy: 0.6665\n",
      "Epoch 21/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 0.7849 - \n",
      "2036/2036 [==============================] - 15s 7ms/step - loss: 0.7849 - accuracy: 0.7593 - val_loss: 1.4244 - val_accuracy: 0.6553\n",
      "Epoch 22/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 0.7703 - \n",
      "2036/2036 [==============================] - 18s 9ms/step - loss: 0.7704 - accuracy: 0.7630 - val_loss: 1.3797 - val_accuracy: 0.6683\n",
      "Epoch 23/40\n",
      "227/227 [==============================] - 1s 2ms/step loss: 0.761\n",
      "2036/2036 [==============================] - 15s 7ms/step - loss: 0.7613 - accuracy: 0.7652 - val_loss: 1.4022 - val_accuracy: 0.6601\n",
      "Epoch 24/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 0.7509 - accura\n",
      "2036/2036 [==============================] - 11s 6ms/step - loss: 0.7509 - accuracy: 0.7704 - val_loss: 1.4108 - val_accuracy: 0.6634\n",
      "Epoch 25/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 0.7432 - accu\n",
      "2036/2036 [==============================] - 11s 5ms/step - loss: 0.7430 - accuracy: 0.7719 - val_loss: 1.4584 - val_accuracy: 0.6503\n",
      "Epoch 26/40\n",
      "227/227 [==============================] - 1s 3ms/step los\n",
      "2036/2036 [==============================] - 17s 8ms/step - loss: 0.7348 - accuracy: 0.7729 - val_loss: 1.4617 - val_accuracy: 0.6553\n",
      "Epoch 27/40\n",
      "227/227 [==============================] - 1s 4ms/step\n",
      "2036/2036 [==============================] - 23s 11ms/step - loss: 0.7273 - accuracy: 0.7765 - val_loss: 1.4866 - val_accuracy: 0.6536\n",
      "Epoch 28/40\n",
      "227/227 [==============================] - 1s 4ms/step\n",
      "Epoch 28 - F1 Score: 0.6665\n",
      "Saved best model\n",
      "[0.5418684902723947, 0.5773995173326363, 0.5990375093601406, 0.6228266641472865, 0.6348700823131541, 0.6315542857791329, 0.624950752853186, 0.6496610214955467, 0.647572024492675, 0.6415453871385582, 0.6542437823237546, 0.6519015581660605, 0.6550412096734055, 0.6602870862159756, 0.6471994682949284, 0.6439878957317533, 0.6516646039072213, 0.6625456125860082, 0.6524540077027776, 0.659532043460653, 0.6435482208841877, 0.6623328369129152, 0.6556922861549437, 0.6569135871260018, 0.6426734634165964, 0.6533364455253259, 0.6482584641599785, 0.6665222093008697]\n",
      "2036/2036 [==============================] - 22s 11ms/step - loss: 0.7186 - accuracy: 0.7777 - val_loss: 1.3983 - val_accuracy: 0.6692\n",
      "Epoch 29/40\n",
      "227/227 [==============================] - 1s 3ms/step los\n",
      "2036/2036 [==============================] - 19s 9ms/step - loss: 0.7072 - accuracy: 0.7805 - val_loss: 1.4653 - val_accuracy: 0.6625\n",
      "Epoch 30/40\n",
      "227/227 [==============================] - 1s 3ms/step l\n",
      "2036/2036 [==============================] - 18s 9ms/step - loss: 0.7022 - accuracy: 0.7815 - val_loss: 1.4714 - val_accuracy: 0.6647\n",
      "Epoch 31/40\n",
      "227/227 [==============================] - 1s 3ms/step los\n",
      "2036/2036 [==============================] - 24s 12ms/step - loss: 0.6933 - accuracy: 0.7831 - val_loss: 1.5182 - val_accuracy: 0.6574\n",
      "Epoch 32/40\n",
      "227/227 [==============================] - 1s 3ms/step l\n",
      "2036/2036 [==============================] - 25s 12ms/step - loss: 0.6878 - accuracy: 0.7862 - val_loss: 1.5283 - val_accuracy: 0.6688\n",
      "Epoch 33/40\n",
      "227/227 [==============================] - 1s 3ms/step los\n",
      "2036/2036 [==============================] - 28s 14ms/step - loss: 0.6812 - accuracy: 0.7856 - val_loss: 1.5453 - val_accuracy: 0.6574\n",
      "Epoch 34/40\n",
      "227/227 [==============================] - 1s 3ms/step lo\n",
      "2036/2036 [==============================] - 20s 10ms/step - loss: 0.6686 - accuracy: 0.7901 - val_loss: 1.5185 - val_accuracy: 0.6643\n",
      "Epoch 35/40\n",
      "227/227 [==============================] - 1s 3ms/step lo\n",
      "2036/2036 [==============================] - 24s 12ms/step - loss: 0.6665 - accuracy: 0.7906 - val_loss: 1.5169 - val_accuracy: 0.6679\n",
      "Epoch 36/40\n",
      "227/227 [==============================] - 1s 3ms/step los\n",
      "2036/2036 [==============================] - 27s 13ms/step - loss: 0.6596 - accuracy: 0.7942 - val_loss: 1.5834 - val_accuracy: 0.6511\n",
      "Epoch 37/40\n",
      "227/227 [==============================] - 1s 3ms/step los\n",
      "2036/2036 [==============================] - 27s 13ms/step - loss: 0.6524 - accuracy: 0.7953 - val_loss: 1.6229 - val_accuracy: 0.6529\n",
      "Epoch 38/40\n",
      "227/227 [==============================] - 1s 4ms/step\n",
      "2036/2036 [==============================] - 23s 11ms/step - loss: 0.6496 - accuracy: 0.7963 - val_loss: 1.6170 - val_accuracy: 0.6565\n",
      "Epoch 39/40\n",
      "227/227 [==============================] - 1s 4ms/step\n",
      "2036/2036 [==============================] - 23s 11ms/step - loss: 0.6395 - accuracy: 0.7975 - val_loss: 1.6115 - val_accuracy: 0.6571\n",
      "Epoch 40/40\n",
      "227/227 [==============================] - 1s 3ms/step loss\n",
      "2036/2036 [==============================] - 22s 11ms/step - loss: 0.6343 - accuracy: 0.7996 - val_loss: 1.6430 - val_accuracy: 0.6556\n",
      "402/402 [==============================] - 1s 3ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         119     0.8339    0.4879    0.6156      1070\n",
      "         120     0.3011    0.8112    0.4392       196\n",
      "         125     0.5305    0.7857    0.6333       532\n",
      "         134     0.3784    0.7368    0.5000        19\n",
      "         190     0.6611    0.7900    0.7198       200\n",
      "          20     0.4990    0.2963    0.3718       810\n",
      "         200     0.7568    0.4695    0.5795       590\n",
      "         203     0.5667    0.6296    0.5965        27\n",
      "          22     0.7509    0.8436    0.7945       518\n",
      "         269     0.2808    0.3868    0.3254       106\n",
      "         276     0.2642    0.2188    0.2393        64\n",
      "         287     0.4330    0.5895    0.4993       285\n",
      "         295     0.5714    0.6420    0.6047        81\n",
      "         306     0.2442    0.4468    0.3158        94\n",
      "         312     0.2222    0.0952    0.1333        42\n",
      "         319     0.2015    0.5294    0.2919        51\n",
      "         326     0.3529    0.3871    0.3692        31\n",
      "         327     0.3333    0.1143    0.1702        35\n",
      "         345     0.2727    0.2308    0.2500        26\n",
      "         347     0.4333    0.5417    0.4815        24\n",
      "         352     0.5351    0.8742    0.6639       453\n",
      "         362     0.5882    0.7377    0.6545       122\n",
      "         400     0.3269    0.2464    0.2810       138\n",
      "         401     0.4762    0.5769    0.5217        52\n",
      "         415     0.7273    0.5714    0.6400        42\n",
      "         416     0.6763    0.7908    0.7291       325\n",
      "         426     0.5000    0.5476    0.5227        42\n",
      "         427     0.6667    0.3636    0.4706        44\n",
      "         434     0.2811    0.8608    0.4239       194\n",
      "         476     0.7406    0.7937    0.7662       223\n",
      "         502     0.4598    0.7477    0.5694       107\n",
      "         522     0.4889    0.4889    0.4889        90\n",
      "         532     0.4167    0.6818    0.5172        44\n",
      "          59     0.6457    0.7523    0.6949       109\n",
      "         601     0.2983    0.7606    0.4286        71\n",
      "         611     0.5785    0.7609    0.6573        92\n",
      "         617     0.5278    0.5000    0.5135        38\n",
      "         639     0.1429    0.5000    0.2222        28\n",
      "         668     0.0694    0.1111    0.0855        45\n",
      "         732     0.2785    0.2245    0.2486        98\n",
      "          74     0.0578    0.2254    0.0920        71\n",
      "         755     0.3056    0.3929    0.3438        28\n",
      "          77     0.5362    0.2500    0.3410       148\n",
      "         770     0.2632    0.2542    0.2586        59\n",
      "         772     0.5714    0.3529    0.4364        34\n",
      "          78     0.4692    0.7973    0.5907       296\n",
      "         787     0.7305    0.3989    0.5160       890\n",
      "          79     0.9834    0.4987    0.6618      2256\n",
      "         798     0.7941    0.6279    0.7013       129\n",
      "         835     0.3377    0.6341    0.4407        41\n",
      "         843     0.5000    0.6471    0.5641        34\n",
      "         862     0.4035    0.6273    0.4911       220\n",
      "         863     0.4516    0.1186    0.1879       118\n",
      "          89     0.9789    0.6803    0.8027       957\n",
      "         908     0.3077    0.3333    0.3200        24\n",
      "         918     0.2045    0.8111    0.3266        90\n",
      "          94     0.3877    0.5377    0.4505       292\n",
      "\n",
      "    accuracy                         0.5633     12845\n",
      "   macro avg     0.4666    0.5283    0.4659     12845\n",
      "weighted avg     0.6717    0.5633    0.5765     12845\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['label_encoder_train.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import joblib\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class F1ScoreCallback(Callback):\n",
    "    def __init__(self, X_val, y_val):\n",
    "        super(F1ScoreCallback, self).__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.best_f1 = 0.0\n",
    "        self.best_model = None\n",
    "        self.f1_scores = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_val_pred = np.argmax(self.model.predict(self.X_val), axis=1)\n",
    "        f1 = f1_score(self.y_val, y_val_pred, average='weighted')\n",
    "        self.f1_scores.append(f1)\n",
    "        \n",
    "\n",
    "        if f1 > self.best_f1:\n",
    "            self.best_f1 = f1\n",
    "            self.best_model = self.model\n",
    "            print(f\"Epoch {epoch + 1} - F1 Score: {f1:.4f}\")\n",
    "            print(\"Saved best model\")\n",
    "            print(self.f1_scores)\n",
    "\n",
    "with open('train_phi_descr_comparison.pickle', 'rb') as f1:\n",
    "    balanced = pickle.load(f1)\n",
    "\n",
    "with open('test_phi_descr_comparison.pickle', 'rb') as f2:\n",
    "    unbalanced = pickle.load(f2)\n",
    "\n",
    "train = np.array([item['cve_description_phi'] for item in balanced if item['cwe'] != 'None'])\n",
    "test = np.array([item['cwe'] for item in balanced if item['cwe'] != 'None'])\n",
    "np.random.seed(42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(train,test,test_size=0.1,random_state=42)\n",
    "\n",
    "X_test = np.array([item['cve_description_phi'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "y_test = np.array([item['cwe'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "\n",
    "label_encoder_train = LabelEncoder()\n",
    "y_train_encoded = label_encoder_train.fit_transform(y_train)\n",
    "label_encoder_test = LabelEncoder()\n",
    "y_test_encoded = label_encoder_test.fit_transform(y_test)\n",
    "\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = len(np.unique(y_train))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "f1_callback = F1ScoreCallback(X_val, label_encoder_train.transform(y_val))\n",
    "\n",
    "history = model.fit(X_train, y_train_encoded, epochs=40, batch_size=32, validation_data=(X_val, label_encoder_train.transform(y_val)), verbose=1, callbacks=[f1_callback])\n",
    "\n",
    "best_model = f1_callback.best_model\n",
    "\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model, 'CWE_classes.joblib')\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_probs = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "y_pred_original = label_encoder_train.inverse_transform(y_pred)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_original, digits=4))\n",
    "\n",
    "joblib.dump(label_encoder_train, 'label_encoder_train.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference based on CVE description with Phi-2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 [==============================] - 20s 49ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         119     0.8339    0.4879    0.6156      1070\n",
      "         120     0.3011    0.8112    0.4392       196\n",
      "         125     0.5305    0.7857    0.6333       532\n",
      "         134     0.3784    0.7368    0.5000        19\n",
      "         190     0.6611    0.7900    0.7198       200\n",
      "          20     0.4990    0.2963    0.3718       810\n",
      "         200     0.7568    0.4695    0.5795       590\n",
      "         203     0.5667    0.6296    0.5965        27\n",
      "          22     0.7509    0.8436    0.7945       518\n",
      "         269     0.2808    0.3868    0.3254       106\n",
      "         276     0.2642    0.2188    0.2393        64\n",
      "         287     0.4330    0.5895    0.4993       285\n",
      "         295     0.5714    0.6420    0.6047        81\n",
      "         306     0.2442    0.4468    0.3158        94\n",
      "         312     0.2222    0.0952    0.1333        42\n",
      "         319     0.2015    0.5294    0.2919        51\n",
      "         326     0.3529    0.3871    0.3692        31\n",
      "         327     0.3333    0.1143    0.1702        35\n",
      "         345     0.2727    0.2308    0.2500        26\n",
      "         347     0.4333    0.5417    0.4815        24\n",
      "         352     0.5351    0.8742    0.6639       453\n",
      "         362     0.5882    0.7377    0.6545       122\n",
      "         400     0.3269    0.2464    0.2810       138\n",
      "         401     0.4762    0.5769    0.5217        52\n",
      "         415     0.7273    0.5714    0.6400        42\n",
      "         416     0.6763    0.7908    0.7291       325\n",
      "         426     0.5000    0.5476    0.5227        42\n",
      "         427     0.6667    0.3636    0.4706        44\n",
      "         434     0.2811    0.8608    0.4239       194\n",
      "         476     0.7406    0.7937    0.7662       223\n",
      "         502     0.4598    0.7477    0.5694       107\n",
      "         522     0.4889    0.4889    0.4889        90\n",
      "         532     0.4167    0.6818    0.5172        44\n",
      "          59     0.6457    0.7523    0.6949       109\n",
      "         601     0.2983    0.7606    0.4286        71\n",
      "         611     0.5785    0.7609    0.6573        92\n",
      "         617     0.5278    0.5000    0.5135        38\n",
      "         639     0.1429    0.5000    0.2222        28\n",
      "         668     0.0694    0.1111    0.0855        45\n",
      "         732     0.2785    0.2245    0.2486        98\n",
      "          74     0.0578    0.2254    0.0920        71\n",
      "         755     0.3056    0.3929    0.3438        28\n",
      "          77     0.5362    0.2500    0.3410       148\n",
      "         770     0.2632    0.2542    0.2586        59\n",
      "         772     0.5714    0.3529    0.4364        34\n",
      "          78     0.4692    0.7973    0.5907       296\n",
      "         787     0.7305    0.3989    0.5160       890\n",
      "          79     0.9834    0.4987    0.6618      2256\n",
      "         798     0.7941    0.6279    0.7013       129\n",
      "         835     0.3377    0.6341    0.4407        41\n",
      "         843     0.5000    0.6471    0.5641        34\n",
      "         862     0.4035    0.6273    0.4911       220\n",
      "         863     0.4516    0.1186    0.1879       118\n",
      "          89     0.9789    0.6803    0.8027       957\n",
      "         908     0.3077    0.3333    0.3200        24\n",
      "         918     0.2045    0.8111    0.3266        90\n",
      "          94     0.3877    0.5377    0.4505       292\n",
      "\n",
      "    accuracy                         0.5633     12845\n",
      "   macro avg     0.4666    0.5283    0.4659     12845\n",
      "weighted avg     0.6717    0.5633    0.5765     12845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Save the best model\n",
    "with open('test_phi_descr_comparison.pickle', 'rb') as f2:\n",
    "    unbalanced = pickle.load(f2)\n",
    "\n",
    "X_test = np.array([item['cve_description_phi'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "y_test = np.array([item['cwe'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "\n",
    "best_model=joblib.load('CWE_classes.joblib')\n",
    "label_encoder_train=joblib.load('label_encoder_train.joblib')\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_probs = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "y_pred_original = label_encoder_train.inverse_transform(y_pred)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_original, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

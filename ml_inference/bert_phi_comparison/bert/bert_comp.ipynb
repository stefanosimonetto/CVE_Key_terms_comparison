{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for BERT based on CVE descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "227/227 [==============================] - 1s 2ms/step loss: 2.2313 -\n",
      "Epoch 1 - F1 Score: 0.5076\n",
      "Saved best model\n",
      "[0.5075948230656329]\n",
      "2036/2036 [==============================] - 9s 4ms/step - loss: 2.2307 - accuracy: 0.4207 - val_loss: 1.7326 - val_accuracy: 0.5414\n",
      "Epoch 2/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.6546 - accu\n",
      "Epoch 2 - F1 Score: 0.5427\n",
      "Saved best model\n",
      "[0.5075948230656329, 0.5427395495769903]\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 1.6547 - accuracy: 0.5490 - val_loss: 1.5684 - val_accuracy: 0.5743\n",
      "Epoch 3/40\n",
      "227/227 [==============================] - 1s 2ms/step loss: 1.505\n",
      "Epoch 3 - F1 Score: 0.5665\n",
      "Saved best model\n",
      "[0.5075948230656329, 0.5427395495769903, 0.5665084803503982]\n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 1.5054 - accuracy: 0.5885 - val_loss: 1.5118 - val_accuracy: 0.5864\n",
      "Epoch 4/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.4186 - \n",
      "Epoch 4 - F1 Score: 0.5925\n",
      "Saved best model\n",
      "[0.5075948230656329, 0.5427395495769903, 0.5665084803503982, 0.5925263299320995]\n",
      "2036/2036 [==============================] - 8s 4ms/step - loss: 1.4189 - accuracy: 0.6097 - val_loss: 1.3933 - val_accuracy: 0.6142\n",
      "Epoch 5/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.3543 - accura\n",
      "Epoch 5 - F1 Score: 0.6025\n",
      "Saved best model\n",
      "[0.5075948230656329, 0.5427395495769903, 0.5665084803503982, 0.5925263299320995, 0.602548784258636]\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 1.3548 - accuracy: 0.6264 - val_loss: 1.3627 - val_accuracy: 0.6214\n",
      "Epoch 6/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.3111 - \n",
      "Epoch 6 - F1 Score: 0.6110\n",
      "Saved best model\n",
      "[0.5075948230656329, 0.5427395495769903, 0.5665084803503982, 0.5925263299320995, 0.602548784258636, 0.6110330804256319]\n",
      "2036/2036 [==============================] - 8s 4ms/step - loss: 1.3112 - accuracy: 0.6349 - val_loss: 1.3736 - val_accuracy: 0.6255\n",
      "Epoch 7/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.2759 \n",
      "Epoch 7 - F1 Score: 0.6193\n",
      "Saved best model\n",
      "[0.5075948230656329, 0.5427395495769903, 0.5665084803503982, 0.5925263299320995, 0.602548784258636, 0.6110330804256319, 0.6193107892721205]\n",
      "2036/2036 [==============================] - 8s 4ms/step - loss: 1.2759 - accuracy: 0.6442 - val_loss: 1.3112 - val_accuracy: 0.6374\n",
      "Epoch 8/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.2406 \n",
      "Epoch 8 - F1 Score: 0.6236\n",
      "Saved best model\n",
      "[0.5075948230656329, 0.5427395495769903, 0.5665084803503982, 0.5925263299320995, 0.602548784258636, 0.6110330804256319, 0.6193107892721205, 0.6236313849128985]\n",
      "2036/2036 [==============================] - 5s 2ms/step - loss: 1.2413 - accuracy: 0.6528 - val_loss: 1.2946 - val_accuracy: 0.6435\n",
      "Epoch 9/40\n",
      "227/227 [==============================] - 0s 906us/steposs: 1.2195 - accura\n",
      "Epoch 9 - F1 Score: 0.6250\n",
      "Saved best model\n",
      "[0.5075948230656329, 0.5427395495769903, 0.5665084803503982, 0.5925263299320995, 0.602548784258636, 0.6110330804256319, 0.6193107892721205, 0.6236313849128985, 0.6250039815419781]\n",
      "2036/2036 [==============================] - 5s 2ms/step - loss: 1.2203 - accuracy: 0.6577 - val_loss: 1.2887 - val_accuracy: 0.6452\n",
      "Epoch 10/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.1963 - accura\n",
      "Epoch 10 - F1 Score: 0.6255\n",
      "Saved best model\n",
      "[0.5075948230656329, 0.5427395495769903, 0.5665084803503982, 0.5925263299320995, 0.602548784258636, 0.6110330804256319, 0.6193107892721205, 0.6236313849128985, 0.6250039815419781, 0.6254868163281292]\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 1.1962 - accuracy: 0.6632 - val_loss: 1.2659 - val_accuracy: 0.6447\n",
      "Epoch 11/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.1783 - accu\n",
      "Epoch 11 - F1 Score: 0.6431\n",
      "Saved best model\n",
      "[0.5075948230656329, 0.5427395495769903, 0.5665084803503982, 0.5925263299320995, 0.602548784258636, 0.6110330804256319, 0.6193107892721205, 0.6236313849128985, 0.6250039815419781, 0.6254868163281292, 0.6431042204840675]\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 1.1786 - accuracy: 0.6682 - val_loss: 1.2415 - val_accuracy: 0.6519\n",
      "Epoch 12/40\n",
      "227/227 [==============================] - 0s 936us/steposs: 1.1587 - accura\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 1.1599 - accuracy: 0.6736 - val_loss: 1.2622 - val_accuracy: 0.6501\n",
      "Epoch 13/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.1428 - accu\n",
      "2036/2036 [==============================] - 5s 3ms/step - loss: 1.1423 - accuracy: 0.6766 - val_loss: 1.2633 - val_accuracy: 0.6475\n",
      "Epoch 14/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.1295 - \n",
      "Epoch 14 - F1 Score: 0.6476\n",
      "Saved best model\n",
      "[0.5075948230656329, 0.5427395495769903, 0.5665084803503982, 0.5925263299320995, 0.602548784258636, 0.6110330804256319, 0.6193107892721205, 0.6236313849128985, 0.6250039815419781, 0.6254868163281292, 0.6431042204840675, 0.6397551970954587, 0.6334084572284788, 0.6476180155940087]\n",
      "2036/2036 [==============================] - 8s 4ms/step - loss: 1.1295 - accuracy: 0.6799 - val_loss: 1.2264 - val_accuracy: 0.6635\n",
      "Epoch 15/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.1132 \n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 1.1133 - accuracy: 0.6831 - val_loss: 1.2637 - val_accuracy: 0.6476\n",
      "Epoch 16/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.0982 - \n",
      "Epoch 16 - F1 Score: 0.6513\n",
      "Saved best model\n",
      "[0.5075948230656329, 0.5427395495769903, 0.5665084803503982, 0.5925263299320995, 0.602548784258636, 0.6110330804256319, 0.6193107892721205, 0.6236313849128985, 0.6250039815419781, 0.6254868163281292, 0.6431042204840675, 0.6397551970954587, 0.6334084572284788, 0.6476180155940087, 0.6340517822503516, 0.6513420570937993]\n",
      "2036/2036 [==============================] - 7s 4ms/step - loss: 1.0985 - accuracy: 0.6879 - val_loss: 1.2475 - val_accuracy: 0.6575\n",
      "Epoch 17/40\n",
      "227/227 [==============================] - 0s 943us/steposs: 1.0913 - accura\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 1.0909 - accuracy: 0.6904 - val_loss: 1.2528 - val_accuracy: 0.6579\n",
      "Epoch 18/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.0775 - \n",
      "2036/2036 [==============================] - 5s 3ms/step - loss: 1.0775 - accuracy: 0.6921 - val_loss: 1.2578 - val_accuracy: 0.6569\n",
      "Epoch 19/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.0658 \n",
      "Epoch 19 - F1 Score: 0.6549\n",
      "Saved best model\n",
      "[0.5075948230656329, 0.5427395495769903, 0.5665084803503982, 0.5925263299320995, 0.602548784258636, 0.6110330804256319, 0.6193107892721205, 0.6236313849128985, 0.6250039815419781, 0.6254868163281292, 0.6431042204840675, 0.6397551970954587, 0.6334084572284788, 0.6476180155940087, 0.6340517822503516, 0.6513420570937993, 0.6450022593655285, 0.6453921779273254, 0.6549236546249798]\n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 1.0657 - accuracy: 0.6967 - val_loss: 1.2593 - val_accuracy: 0.6628\n",
      "Epoch 20/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.0536 - accu\n",
      "2036/2036 [==============================] - 8s 4ms/step - loss: 1.0536 - accuracy: 0.6983 - val_loss: 1.2409 - val_accuracy: 0.6599\n",
      "Epoch 21/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.0433 - ac\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 1.0446 - accuracy: 0.7011 - val_loss: 1.2190 - val_accuracy: 0.6624\n",
      "Epoch 22/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.0353 - \n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 1.0357 - accuracy: 0.7023 - val_loss: 1.2477 - val_accuracy: 0.6609\n",
      "Epoch 23/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.0246 - ac\n",
      "Epoch 23 - F1 Score: 0.6595\n",
      "Saved best model\n",
      "[0.5075948230656329, 0.5427395495769903, 0.5665084803503982, 0.5925263299320995, 0.602548784258636, 0.6110330804256319, 0.6193107892721205, 0.6236313849128985, 0.6250039815419781, 0.6254868163281292, 0.6431042204840675, 0.6397551970954587, 0.6334084572284788, 0.6476180155940087, 0.6340517822503516, 0.6513420570937993, 0.6450022593655285, 0.6453921779273254, 0.6549236546249798, 0.6456480456648427, 0.6506934436654223, 0.6501196551388223, 0.6595202948843608]\n",
      "2036/2036 [==============================] - 7s 4ms/step - loss: 1.0246 - accuracy: 0.7055 - val_loss: 1.1988 - val_accuracy: 0.6742\n",
      "Epoch 24/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.0169 \n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 1.0173 - accuracy: 0.7068 - val_loss: 1.1906 - val_accuracy: 0.6709\n",
      "Epoch 25/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.0061 - \n",
      "2036/2036 [==============================] - 8s 4ms/step - loss: 1.0062 - accuracy: 0.7097 - val_loss: 1.2332 - val_accuracy: 0.6630\n",
      "Epoch 26/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 0.9982 - \n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 0.9981 - accuracy: 0.7118 - val_loss: 1.2247 - val_accuracy: 0.6692\n",
      "Epoch 27/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 0.9930 - ac\n",
      "Epoch 27 - F1 Score: 0.6642\n",
      "Saved best model\n",
      "[0.5075948230656329, 0.5427395495769903, 0.5665084803503982, 0.5925263299320995, 0.602548784258636, 0.6110330804256319, 0.6193107892721205, 0.6236313849128985, 0.6250039815419781, 0.6254868163281292, 0.6431042204840675, 0.6397551970954587, 0.6334084572284788, 0.6476180155940087, 0.6340517822503516, 0.6513420570937993, 0.6450022593655285, 0.6453921779273254, 0.6549236546249798, 0.6456480456648427, 0.6506934436654223, 0.6501196551388223, 0.6595202948843608, 0.6576469894580214, 0.6511729632251744, 0.6558505561011505, 0.6641989755528449]\n",
      "2036/2036 [==============================] - 7s 4ms/step - loss: 0.9931 - accuracy: 0.7136 - val_loss: 1.2044 - val_accuracy: 0.6722\n",
      "Epoch 28/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 0.9867 \n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 0.9875 - accuracy: 0.7140 - val_loss: 1.2137 - val_accuracy: 0.6718\n",
      "Epoch 29/40\n",
      "227/227 [==============================] - 0s 913us/steposs: 0.9789 - accura\n",
      "2036/2036 [==============================] - 5s 2ms/step - loss: 0.9790 - accuracy: 0.7160 - val_loss: 1.2106 - val_accuracy: 0.6703\n",
      "Epoch 30/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 0.9706 - accura\n",
      "Epoch 30 - F1 Score: 0.6648\n",
      "Saved best model\n",
      "[0.5075948230656329, 0.5427395495769903, 0.5665084803503982, 0.5925263299320995, 0.602548784258636, 0.6110330804256319, 0.6193107892721205, 0.6236313849128985, 0.6250039815419781, 0.6254868163281292, 0.6431042204840675, 0.6397551970954587, 0.6334084572284788, 0.6476180155940087, 0.6340517822503516, 0.6513420570937993, 0.6450022593655285, 0.6453921779273254, 0.6549236546249798, 0.6456480456648427, 0.6506934436654223, 0.6501196551388223, 0.6595202948843608, 0.6576469894580214, 0.6511729632251744, 0.6558505561011505, 0.6641989755528449, 0.6609843901842756, 0.663122024727359, 0.6648095754465035]\n",
      "2036/2036 [==============================] - 5s 2ms/step - loss: 0.9717 - accuracy: 0.7172 - val_loss: 1.2267 - val_accuracy: 0.6709\n",
      "Epoch 31/40\n",
      "227/227 [==============================] - 0s 963us/steposs: 0.9629 - accura\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 0.9633 - accuracy: 0.7201 - val_loss: 1.2239 - val_accuracy: 0.6656\n",
      "Epoch 32/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 0.9565 - accura\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 0.9566 - accuracy: 0.7199 - val_loss: 1.2264 - val_accuracy: 0.6692\n",
      "Epoch 33/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 0.9527 - \n",
      "Epoch 33 - F1 Score: 0.6653\n",
      "Saved best model\n",
      "[0.5075948230656329, 0.5427395495769903, 0.5665084803503982, 0.5925263299320995, 0.602548784258636, 0.6110330804256319, 0.6193107892721205, 0.6236313849128985, 0.6250039815419781, 0.6254868163281292, 0.6431042204840675, 0.6397551970954587, 0.6334084572284788, 0.6476180155940087, 0.6340517822503516, 0.6513420570937993, 0.6450022593655285, 0.6453921779273254, 0.6549236546249798, 0.6456480456648427, 0.6506934436654223, 0.6501196551388223, 0.6595202948843608, 0.6576469894580214, 0.6511729632251744, 0.6558505561011505, 0.6641989755528449, 0.6609843901842756, 0.663122024727359, 0.6648095754465035, 0.6632371928953414, 0.6608995192315961, 0.665345363410496]\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 0.9527 - accuracy: 0.7210 - val_loss: 1.2363 - val_accuracy: 0.6666\n",
      "Epoch 34/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 0.9441 - accura\n",
      "Epoch 34 - F1 Score: 0.6680\n",
      "Saved best model\n",
      "[0.5075948230656329, 0.5427395495769903, 0.5665084803503982, 0.5925263299320995, 0.602548784258636, 0.6110330804256319, 0.6193107892721205, 0.6236313849128985, 0.6250039815419781, 0.6254868163281292, 0.6431042204840675, 0.6397551970954587, 0.6334084572284788, 0.6476180155940087, 0.6340517822503516, 0.6513420570937993, 0.6450022593655285, 0.6453921779273254, 0.6549236546249798, 0.6456480456648427, 0.6506934436654223, 0.6501196551388223, 0.6595202948843608, 0.6576469894580214, 0.6511729632251744, 0.6558505561011505, 0.6641989755528449, 0.6609843901842756, 0.663122024727359, 0.6648095754465035, 0.6632371928953414, 0.6608995192315961, 0.665345363410496, 0.6679920715747606]\n",
      "2036/2036 [==============================] - 5s 2ms/step - loss: 0.9434 - accuracy: 0.7247 - val_loss: 1.2015 - val_accuracy: 0.6771\n",
      "Epoch 35/40\n",
      "227/227 [==============================] - 0s 960us/steposs: 0.9392 - accura\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 0.9397 - accuracy: 0.7263 - val_loss: 1.2155 - val_accuracy: 0.6700\n",
      "Epoch 36/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 0.9352 - accura\n",
      "Epoch 36 - F1 Score: 0.6686\n",
      "Saved best model\n",
      "[0.5075948230656329, 0.5427395495769903, 0.5665084803503982, 0.5925263299320995, 0.602548784258636, 0.6110330804256319, 0.6193107892721205, 0.6236313849128985, 0.6250039815419781, 0.6254868163281292, 0.6431042204840675, 0.6397551970954587, 0.6334084572284788, 0.6476180155940087, 0.6340517822503516, 0.6513420570937993, 0.6450022593655285, 0.6453921779273254, 0.6549236546249798, 0.6456480456648427, 0.6506934436654223, 0.6501196551388223, 0.6595202948843608, 0.6576469894580214, 0.6511729632251744, 0.6558505561011505, 0.6641989755528449, 0.6609843901842756, 0.663122024727359, 0.6648095754465035, 0.6632371928953414, 0.6608995192315961, 0.665345363410496, 0.6679920715747606, 0.6649032001533434, 0.668632280730021]\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 0.9350 - accuracy: 0.7252 - val_loss: 1.2290 - val_accuracy: 0.6733\n",
      "Epoch 37/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 0.9294 - accura\n",
      "Epoch 37 - F1 Score: 0.6687\n",
      "Saved best model\n",
      "[0.5075948230656329, 0.5427395495769903, 0.5665084803503982, 0.5925263299320995, 0.602548784258636, 0.6110330804256319, 0.6193107892721205, 0.6236313849128985, 0.6250039815419781, 0.6254868163281292, 0.6431042204840675, 0.6397551970954587, 0.6334084572284788, 0.6476180155940087, 0.6340517822503516, 0.6513420570937993, 0.6450022593655285, 0.6453921779273254, 0.6549236546249798, 0.6456480456648427, 0.6506934436654223, 0.6501196551388223, 0.6595202948843608, 0.6576469894580214, 0.6511729632251744, 0.6558505561011505, 0.6641989755528449, 0.6609843901842756, 0.663122024727359, 0.6648095754465035, 0.6632371928953414, 0.6608995192315961, 0.665345363410496, 0.6679920715747606, 0.6649032001533434, 0.668632280730021, 0.6686735174223424]\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 0.9296 - accuracy: 0.7272 - val_loss: 1.2152 - val_accuracy: 0.6724\n",
      "Epoch 38/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 0.9243 - accura\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 0.9235 - accuracy: 0.7276 - val_loss: 1.2223 - val_accuracy: 0.6745\n",
      "Epoch 39/40\n",
      "227/227 [==============================] - 0s 913us/steposs: 0.9171 - accura\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 0.9180 - accuracy: 0.7299 - val_loss: 1.2428 - val_accuracy: 0.6686\n",
      "Epoch 40/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 0.9122 - accura\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 0.9125 - accuracy: 0.7336 - val_loss: 1.2407 - val_accuracy: 0.6714\n",
      "402/402 [==============================] - 0s 932us/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         119     0.8668    0.4318    0.5764      1070\n",
      "         120     0.4715    0.6327    0.5403       196\n",
      "         125     0.6442    0.8271    0.7243       532\n",
      "         134     0.3793    0.5789    0.4583        19\n",
      "         190     0.6996    0.8150    0.7529       200\n",
      "          20     0.4914    0.3160    0.3847       810\n",
      "         200     0.7224    0.4763    0.5741       590\n",
      "         203     0.4375    0.5185    0.4746        27\n",
      "          22     0.8185    0.8359    0.8271       518\n",
      "         269     0.1909    0.4340    0.2651       106\n",
      "         276     0.2143    0.1875    0.2000        64\n",
      "         287     0.3859    0.6526    0.4850       285\n",
      "         295     0.4574    0.7284    0.5619        81\n",
      "         306     0.1643    0.2447    0.1966        94\n",
      "         312     0.2273    0.2381    0.2326        42\n",
      "         319     0.6000    0.2941    0.3947        51\n",
      "         326     0.1935    0.1935    0.1935        31\n",
      "         327     0.3611    0.3714    0.3662        35\n",
      "         345     0.1081    0.1538    0.1270        26\n",
      "         347     0.2917    0.5833    0.3889        24\n",
      "         352     0.5815    0.8587    0.6934       453\n",
      "         362     0.5556    0.6557    0.6015       122\n",
      "         400     0.3594    0.3333    0.3459       138\n",
      "         401     0.5283    0.5385    0.5333        52\n",
      "         415     0.4583    0.2619    0.3333        42\n",
      "         416     0.7699    0.8646    0.8145       325\n",
      "         426     0.4030    0.6429    0.4954        42\n",
      "         427     0.4918    0.6818    0.5714        44\n",
      "         434     0.4039    0.8557    0.5488       194\n",
      "         476     0.5601    0.8565    0.6773       223\n",
      "         502     0.5000    0.5234    0.5114       107\n",
      "         522     0.4737    0.4000    0.4337        90\n",
      "         532     0.4490    0.5000    0.4731        44\n",
      "          59     0.6293    0.6697    0.6489       109\n",
      "         601     0.3613    0.7887    0.4956        71\n",
      "         611     0.6286    0.7174    0.6701        92\n",
      "         617     0.4528    0.6316    0.5275        38\n",
      "         639     0.2273    0.3571    0.2778        28\n",
      "         668     0.0400    0.0222    0.0286        45\n",
      "         732     0.1688    0.2755    0.2093        98\n",
      "          74     0.1346    0.3944    0.2007        71\n",
      "         755     0.1096    0.2857    0.1584        28\n",
      "          77     0.4457    0.5270    0.4830       148\n",
      "         770     0.3478    0.2712    0.3048        59\n",
      "         772     0.7333    0.3235    0.4490        34\n",
      "          78     0.6026    0.6351    0.6184       296\n",
      "         787     0.6053    0.6685    0.6353       890\n",
      "          79     0.9911    0.5452    0.7035      2256\n",
      "         798     0.5915    0.6512    0.6199       129\n",
      "         835     0.4630    0.6098    0.5263        41\n",
      "         843     0.3544    0.8235    0.4956        34\n",
      "         862     0.5739    0.6000    0.5867       220\n",
      "         863     0.1536    0.3644    0.2161       118\n",
      "          89     0.9930    0.7388    0.8472       957\n",
      "         908     0.4091    0.3750    0.3913        24\n",
      "         918     0.7222    0.4333    0.5417        90\n",
      "          94     0.3069    0.6096    0.4083       292\n",
      "\n",
      "    accuracy                         0.5910     12845\n",
      "   macro avg     0.4615    0.5229    0.4702     12845\n",
      "weighted avg     0.6779    0.5910    0.6041     12845\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['label_encoder_train_descr.joblib']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import joblib\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class F1ScoreCallback(Callback):\n",
    "    def __init__(self, X_val, y_val):\n",
    "        super(F1ScoreCallback, self).__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.best_f1 = 0.0\n",
    "        self.best_model = None\n",
    "        self.f1_scores = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_val_pred = np.argmax(self.model.predict(self.X_val), axis=1)\n",
    "        f1 = f1_score(self.y_val, y_val_pred, average='weighted')\n",
    "        self.f1_scores.append(f1)\n",
    "        \n",
    "\n",
    "        if f1 > self.best_f1:\n",
    "            self.best_f1 = f1\n",
    "            self.best_model = self.model\n",
    "            print(f\"Epoch {epoch + 1} - F1 Score: {f1:.4f}\")\n",
    "            print(\"Saved best model\")\n",
    "            print(self.f1_scores)\n",
    "\n",
    "with open('train_bert_comp.pickle', 'rb') as f1:\n",
    "    balanced = pickle.load(f1)\n",
    "\n",
    "with open('bert_comparison_test.pickle', 'rb') as f2:\n",
    "    unbalanced = pickle.load(f2)\n",
    "\n",
    "train = np.array([item['cve_description_bert_mean'].tolist() for item in balanced if item['cwe'] != 'None'])\n",
    "\n",
    "test = np.array([item['cwe'] for item in balanced if item['cwe'] != 'None'])\n",
    "np.random.seed(42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(train,test,test_size=0.1,random_state=42)\n",
    "\n",
    "X_test = np.array([item['cve_description_bert_mean'].tolist() for item in unbalanced if item['cwe'] != 'None'])\n",
    "y_test = np.array([item['cwe'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "\n",
    "label_encoder_train = LabelEncoder()\n",
    "y_train_encoded = label_encoder_train.fit_transform(y_train)\n",
    "label_encoder_test = LabelEncoder()\n",
    "y_test_encoded = label_encoder_test.fit_transform(y_test)\n",
    "\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = len(np.unique(y_train))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "f1_callback = F1ScoreCallback(X_val, label_encoder_train.transform(y_val))\n",
    "\n",
    "history = model.fit(X_train, y_train_encoded, epochs=40, batch_size=32, validation_data=(X_val, label_encoder_train.transform(y_val)), verbose=1, callbacks=[f1_callback])\n",
    "\n",
    "best_model = f1_callback.best_model\n",
    "\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model, 'best_model_descr.joblib')\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_probs = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "y_pred_original = label_encoder_train.inverse_transform(y_pred)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_original, digits=4))\n",
    "\n",
    "joblib.dump(label_encoder_train, 'label_encoder_train_descr.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference for CVE description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 [==============================] - 1s 1ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         119     0.8668    0.4318    0.5764      1070\n",
      "         120     0.4715    0.6327    0.5403       196\n",
      "         125     0.6442    0.8271    0.7243       532\n",
      "         134     0.3793    0.5789    0.4583        19\n",
      "         190     0.6996    0.8150    0.7529       200\n",
      "          20     0.4914    0.3160    0.3847       810\n",
      "         200     0.7224    0.4763    0.5741       590\n",
      "         203     0.4375    0.5185    0.4746        27\n",
      "          22     0.8185    0.8359    0.8271       518\n",
      "         269     0.1909    0.4340    0.2651       106\n",
      "         276     0.2143    0.1875    0.2000        64\n",
      "         287     0.3859    0.6526    0.4850       285\n",
      "         295     0.4574    0.7284    0.5619        81\n",
      "         306     0.1643    0.2447    0.1966        94\n",
      "         312     0.2273    0.2381    0.2326        42\n",
      "         319     0.6000    0.2941    0.3947        51\n",
      "         326     0.1935    0.1935    0.1935        31\n",
      "         327     0.3611    0.3714    0.3662        35\n",
      "         345     0.1081    0.1538    0.1270        26\n",
      "         347     0.2917    0.5833    0.3889        24\n",
      "         352     0.5815    0.8587    0.6934       453\n",
      "         362     0.5556    0.6557    0.6015       122\n",
      "         400     0.3594    0.3333    0.3459       138\n",
      "         401     0.5283    0.5385    0.5333        52\n",
      "         415     0.4583    0.2619    0.3333        42\n",
      "         416     0.7699    0.8646    0.8145       325\n",
      "         426     0.4030    0.6429    0.4954        42\n",
      "         427     0.4918    0.6818    0.5714        44\n",
      "         434     0.4039    0.8557    0.5488       194\n",
      "         476     0.5601    0.8565    0.6773       223\n",
      "         502     0.5000    0.5234    0.5114       107\n",
      "         522     0.4737    0.4000    0.4337        90\n",
      "         532     0.4490    0.5000    0.4731        44\n",
      "          59     0.6293    0.6697    0.6489       109\n",
      "         601     0.3613    0.7887    0.4956        71\n",
      "         611     0.6286    0.7174    0.6701        92\n",
      "         617     0.4528    0.6316    0.5275        38\n",
      "         639     0.2273    0.3571    0.2778        28\n",
      "         668     0.0400    0.0222    0.0286        45\n",
      "         732     0.1688    0.2755    0.2093        98\n",
      "          74     0.1346    0.3944    0.2007        71\n",
      "         755     0.1096    0.2857    0.1584        28\n",
      "          77     0.4457    0.5270    0.4830       148\n",
      "         770     0.3478    0.2712    0.3048        59\n",
      "         772     0.7333    0.3235    0.4490        34\n",
      "          78     0.6026    0.6351    0.6184       296\n",
      "         787     0.6053    0.6685    0.6353       890\n",
      "          79     0.9911    0.5452    0.7035      2256\n",
      "         798     0.5915    0.6512    0.6199       129\n",
      "         835     0.4630    0.6098    0.5263        41\n",
      "         843     0.3544    0.8235    0.4956        34\n",
      "         862     0.5739    0.6000    0.5867       220\n",
      "         863     0.1536    0.3644    0.2161       118\n",
      "          89     0.9930    0.7388    0.8472       957\n",
      "         908     0.4091    0.3750    0.3913        24\n",
      "         918     0.7222    0.4333    0.5417        90\n",
      "          94     0.3069    0.6096    0.4083       292\n",
      "\n",
      "    accuracy                         0.5910     12845\n",
      "   macro avg     0.4615    0.5229    0.4702     12845\n",
      "weighted avg     0.6779    0.5910    0.6041     12845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Save the best model\n",
    "with open('bert_comparison_test.pickle', 'rb') as f2:\n",
    "    unbalanced = pickle.load(f2)\n",
    "\n",
    "X_test = np.array([item['cve_description_bert_mean'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "y_test = np.array([item['cwe'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "\n",
    "best_model=joblib.load('best_model_descr.joblib')\n",
    "label_encoder_train=joblib.load('label_encoder_train_descr.joblib')\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_probs = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "y_pred_original = label_encoder_train.inverse_transform(y_pred)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_original, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for BERT based on CVE terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "227/227 [==============================] - 0s 962us/steposs: 2.1700 - accurac\n",
      "Epoch 1 - F1 Score: 0.5107\n",
      "Saved best model\n",
      "[0.5107091911759324]\n",
      "2036/2036 [==============================] - 5s 2ms/step - loss: 2.1641 - accuracy: 0.4342 - val_loss: 1.6560 - val_accuracy: 0.5483\n",
      "Epoch 2/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.5771 - accura\n",
      "Epoch 2 - F1 Score: 0.5734\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414]\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 1.5765 - accuracy: 0.5662 - val_loss: 1.5280 - val_accuracy: 0.5935\n",
      "Epoch 3/40\n",
      "227/227 [==============================] - 0s 873us/steposs: 1.4415 - accuracy\n",
      "Epoch 3 - F1 Score: 0.5818\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929]\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 1.4414 - accuracy: 0.6021 - val_loss: 1.4117 - val_accuracy: 0.6132\n",
      "Epoch 4/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.3695 - accu\n",
      "Epoch 4 - F1 Score: 0.6093\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386]\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 1.3703 - accuracy: 0.6198 - val_loss: 1.3388 - val_accuracy: 0.6349\n",
      "Epoch 5/40\n",
      "227/227 [==============================] - 0s 938us/steposs: 1.3185 - accura\n",
      "Epoch 5 - F1 Score: 0.6216\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613]\n",
      "2036/2036 [==============================] - 5s 2ms/step - loss: 1.3184 - accuracy: 0.6330 - val_loss: 1.2973 - val_accuracy: 0.6421\n",
      "Epoch 6/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.2836 \n",
      "Epoch 6 - F1 Score: 0.6258\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384]\n",
      "2036/2036 [==============================] - 8s 4ms/step - loss: 1.2829 - accuracy: 0.6431 - val_loss: 1.3226 - val_accuracy: 0.6360\n",
      "Epoch 7/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.2489 - accura\n",
      "Epoch 7 - F1 Score: 0.6349\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384, 0.6348785953994661]\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 1.2485 - accuracy: 0.6521 - val_loss: 1.2642 - val_accuracy: 0.6532\n",
      "Epoch 8/40\n",
      "227/227 [==============================] - 0s 973us/steposs: 1.2229 - accura\n",
      "Epoch 8 - F1 Score: 0.6463\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384, 0.6348785953994661, 0.6462574309033058]\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 1.2226 - accuracy: 0.6576 - val_loss: 1.2567 - val_accuracy: 0.6561\n",
      "Epoch 9/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.2072 - accura\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 1.2069 - accuracy: 0.6623 - val_loss: 1.2677 - val_accuracy: 0.6500\n",
      "Epoch 10/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.1863 - ac\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 1.1865 - accuracy: 0.6661 - val_loss: 1.2617 - val_accuracy: 0.6547\n",
      "Epoch 11/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.1688 - ac\n",
      "Epoch 11 - F1 Score: 0.6484\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384, 0.6348785953994661, 0.6462574309033058, 0.6265552948336212, 0.6417515460048598, 0.6483553787627528]\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 1.1688 - accuracy: 0.6727 - val_loss: 1.2207 - val_accuracy: 0.6601\n",
      "Epoch 12/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.1604 \n",
      "Epoch 12 - F1 Score: 0.6514\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384, 0.6348785953994661, 0.6462574309033058, 0.6265552948336212, 0.6417515460048598, 0.6483553787627528, 0.6513983357221315]\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 1.1595 - accuracy: 0.6714 - val_loss: 1.1960 - val_accuracy: 0.6715\n",
      "Epoch 13/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.1454 - ac\n",
      "Epoch 13 - F1 Score: 0.6610\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384, 0.6348785953994661, 0.6462574309033058, 0.6265552948336212, 0.6417515460048598, 0.6483553787627528, 0.6513983357221315, 0.6610218959838702]\n",
      "2036/2036 [==============================] - 7s 4ms/step - loss: 1.1454 - accuracy: 0.6756 - val_loss: 1.1871 - val_accuracy: 0.6758\n",
      "Epoch 14/40\n",
      "227/227 [==============================] - 0s 809us/steposs: 1.1353 - accuracy\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 1.1348 - accuracy: 0.6784 - val_loss: 1.2019 - val_accuracy: 0.6698\n",
      "Epoch 15/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.1231 - \n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 1.1231 - accuracy: 0.6813 - val_loss: 1.1929 - val_accuracy: 0.6666\n",
      "Epoch 16/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.1121 - \n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 1.1122 - accuracy: 0.6846 - val_loss: 1.2080 - val_accuracy: 0.6696\n",
      "Epoch 17/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.1033 - ac\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 1.1033 - accuracy: 0.6870 - val_loss: 1.2092 - val_accuracy: 0.6619\n",
      "Epoch 18/40\n",
      "227/227 [==============================] - 0s 951us/steposs: 1.0951 - accura\n",
      "Epoch 18 - F1 Score: 0.6668\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384, 0.6348785953994661, 0.6462574309033058, 0.6265552948336212, 0.6417515460048598, 0.6483553787627528, 0.6513983357221315, 0.6610218959838702, 0.6590553504489519, 0.6598318937146613, 0.6535911232134137, 0.6515788929148386, 0.66683572272253]\n",
      "2036/2036 [==============================] - 5s 2ms/step - loss: 1.0953 - accuracy: 0.6883 - val_loss: 1.1763 - val_accuracy: 0.6771\n",
      "Epoch 19/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.0848 - accura\n",
      "Epoch 19 - F1 Score: 0.6697\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384, 0.6348785953994661, 0.6462574309033058, 0.6265552948336212, 0.6417515460048598, 0.6483553787627528, 0.6513983357221315, 0.6610218959838702, 0.6590553504489519, 0.6598318937146613, 0.6535911232134137, 0.6515788929148386, 0.66683572272253, 0.6696826282057595]\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 1.0849 - accuracy: 0.6906 - val_loss: 1.1663 - val_accuracy: 0.6821\n",
      "Epoch 20/40\n",
      "227/227 [==============================] - 0s 797us/steposs: 1.0779 - accuracy\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 1.0782 - accuracy: 0.6944 - val_loss: 1.1662 - val_accuracy: 0.6771\n",
      "Epoch 21/40\n",
      "227/227 [==============================] - 0s 961us/steposs: 1.0691 - accura\n",
      "Epoch 21 - F1 Score: 0.6725\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384, 0.6348785953994661, 0.6462574309033058, 0.6265552948336212, 0.6417515460048598, 0.6483553787627528, 0.6513983357221315, 0.6610218959838702, 0.6590553504489519, 0.6598318937146613, 0.6535911232134137, 0.6515788929148386, 0.66683572272253, 0.6696826282057595, 0.6684889703230777, 0.6724607067686212]\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 1.0690 - accuracy: 0.6956 - val_loss: 1.1597 - val_accuracy: 0.6797\n",
      "Epoch 22/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.0635 - accura\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 1.0639 - accuracy: 0.6966 - val_loss: 1.1562 - val_accuracy: 0.6838\n",
      "Epoch 23/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.0582 \n",
      "2036/2036 [==============================] - 5s 2ms/step - loss: 1.0584 - accuracy: 0.6984 - val_loss: 1.1734 - val_accuracy: 0.6785\n",
      "Epoch 24/40\n",
      "227/227 [==============================] - 1s 2ms/step loss: 1.051\n",
      "Epoch 24 - F1 Score: 0.6741\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384, 0.6348785953994661, 0.6462574309033058, 0.6265552948336212, 0.6417515460048598, 0.6483553787627528, 0.6513983357221315, 0.6610218959838702, 0.6590553504489519, 0.6598318937146613, 0.6535911232134137, 0.6515788929148386, 0.66683572272253, 0.6696826282057595, 0.6684889703230777, 0.6724607067686212, 0.6715293190072162, 0.667269965311054, 0.6741365769700944]\n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 1.0510 - accuracy: 0.6972 - val_loss: 1.1619 - val_accuracy: 0.6826\n",
      "Epoch 25/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.0447 - \n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 1.0444 - accuracy: 0.6988 - val_loss: 1.1565 - val_accuracy: 0.6861\n",
      "Epoch 26/40\n",
      "227/227 [==============================] - 1s 2ms/step loss: 1.041\n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 1.0412 - accuracy: 0.7012 - val_loss: 1.1684 - val_accuracy: 0.6801\n",
      "Epoch 27/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.0341 \n",
      "Epoch 27 - F1 Score: 0.6769\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384, 0.6348785953994661, 0.6462574309033058, 0.6265552948336212, 0.6417515460048598, 0.6483553787627528, 0.6513983357221315, 0.6610218959838702, 0.6590553504489519, 0.6598318937146613, 0.6535911232134137, 0.6515788929148386, 0.66683572272253, 0.6696826282057595, 0.6684889703230777, 0.6724607067686212, 0.6715293190072162, 0.667269965311054, 0.6741365769700944, 0.6700199544053506, 0.6678182995052413, 0.6768737172876371]\n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 1.0337 - accuracy: 0.7033 - val_loss: 1.1516 - val_accuracy: 0.6872\n",
      "Epoch 28/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.0296 - ac\n",
      "2036/2036 [==============================] - 7s 4ms/step - loss: 1.0293 - accuracy: 0.7041 - val_loss: 1.1538 - val_accuracy: 0.6815\n",
      "Epoch 29/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.0242 \n",
      "Epoch 29 - F1 Score: 0.6804\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384, 0.6348785953994661, 0.6462574309033058, 0.6265552948336212, 0.6417515460048598, 0.6483553787627528, 0.6513983357221315, 0.6610218959838702, 0.6590553504489519, 0.6598318937146613, 0.6535911232134137, 0.6515788929148386, 0.66683572272253, 0.6696826282057595, 0.6684889703230777, 0.6724607067686212, 0.6715293190072162, 0.667269965311054, 0.6741365769700944, 0.6700199544053506, 0.6678182995052413, 0.6768737172876371, 0.6667157880394359, 0.6803986176238958]\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 1.0242 - accuracy: 0.7070 - val_loss: 1.1335 - val_accuracy: 0.6910\n",
      "Epoch 30/40\n",
      "227/227 [==============================] - 0s 954us/steposs: 1.0216 - accura\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 1.0208 - accuracy: 0.7056 - val_loss: 1.1449 - val_accuracy: 0.6843\n",
      "Epoch 31/40\n",
      "227/227 [==============================] - 0s 906us/steposs: 1.0127 - accura\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 1.0133 - accuracy: 0.7089 - val_loss: 1.1345 - val_accuracy: 0.6902\n",
      "Epoch 32/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.0075 - accura\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 1.0075 - accuracy: 0.7085 - val_loss: 1.1568 - val_accuracy: 0.6844\n",
      "Epoch 33/40\n",
      "227/227 [==============================] - 1s 2ms/step loss: 1.004\n",
      "2036/2036 [==============================] - 7s 4ms/step - loss: 1.0048 - accuracy: 0.7101 - val_loss: 1.1677 - val_accuracy: 0.6812\n",
      "Epoch 34/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.0013 - \n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 1.0013 - accuracy: 0.7102 - val_loss: 1.1754 - val_accuracy: 0.6794\n",
      "Epoch 35/40\n",
      "227/227 [==============================] - 0s 915us/steposs: 0.9968 - accura\n",
      "2036/2036 [==============================] - 5s 3ms/step - loss: 0.9966 - accuracy: 0.7106 - val_loss: 1.1905 - val_accuracy: 0.6754\n",
      "Epoch 36/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 0.9919 \n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 0.9919 - accuracy: 0.7116 - val_loss: 1.1626 - val_accuracy: 0.6833\n",
      "Epoch 37/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 0.9854 - ac\n",
      "Epoch 37 - F1 Score: 0.6815\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384, 0.6348785953994661, 0.6462574309033058, 0.6265552948336212, 0.6417515460048598, 0.6483553787627528, 0.6513983357221315, 0.6610218959838702, 0.6590553504489519, 0.6598318937146613, 0.6535911232134137, 0.6515788929148386, 0.66683572272253, 0.6696826282057595, 0.6684889703230777, 0.6724607067686212, 0.6715293190072162, 0.667269965311054, 0.6741365769700944, 0.6700199544053506, 0.6678182995052413, 0.6768737172876371, 0.6667157880394359, 0.6803986176238958, 0.6710942622427793, 0.6785084562421844, 0.6749746034614327, 0.6670774559710664, 0.6649883990338616, 0.6670127140932592, 0.6699621896736274, 0.6815143232241861]\n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 0.9860 - accuracy: 0.7155 - val_loss: 1.1362 - val_accuracy: 0.6910\n",
      "Epoch 38/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 0.9857 \n",
      "Epoch 38 - F1 Score: 0.6847\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384, 0.6348785953994661, 0.6462574309033058, 0.6265552948336212, 0.6417515460048598, 0.6483553787627528, 0.6513983357221315, 0.6610218959838702, 0.6590553504489519, 0.6598318937146613, 0.6535911232134137, 0.6515788929148386, 0.66683572272253, 0.6696826282057595, 0.6684889703230777, 0.6724607067686212, 0.6715293190072162, 0.667269965311054, 0.6741365769700944, 0.6700199544053506, 0.6678182995052413, 0.6768737172876371, 0.6667157880394359, 0.6803986176238958, 0.6710942622427793, 0.6785084562421844, 0.6749746034614327, 0.6670774559710664, 0.6649883990338616, 0.6670127140932592, 0.6699621896736274, 0.6815143232241861, 0.6847112268680517]\n",
      "2036/2036 [==============================] - 8s 4ms/step - loss: 0.9863 - accuracy: 0.7140 - val_loss: 1.1563 - val_accuracy: 0.6890\n",
      "Epoch 39/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 0.9826 - ac\n",
      "Epoch 39 - F1 Score: 0.6885\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384, 0.6348785953994661, 0.6462574309033058, 0.6265552948336212, 0.6417515460048598, 0.6483553787627528, 0.6513983357221315, 0.6610218959838702, 0.6590553504489519, 0.6598318937146613, 0.6535911232134137, 0.6515788929148386, 0.66683572272253, 0.6696826282057595, 0.6684889703230777, 0.6724607067686212, 0.6715293190072162, 0.667269965311054, 0.6741365769700944, 0.6700199544053506, 0.6678182995052413, 0.6768737172876371, 0.6667157880394359, 0.6803986176238958, 0.6710942622427793, 0.6785084562421844, 0.6749746034614327, 0.6670774559710664, 0.6649883990338616, 0.6670127140932592, 0.6699621896736274, 0.6815143232241861, 0.6847112268680517, 0.6884905163217677]\n",
      "2036/2036 [==============================] - 7s 4ms/step - loss: 0.9830 - accuracy: 0.7149 - val_loss: 1.1306 - val_accuracy: 0.6960\n",
      "Epoch 40/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 0.9789 - accu\n",
      "2036/2036 [==============================] - 5s 2ms/step - loss: 0.9784 - accuracy: 0.7167 - val_loss: 1.1537 - val_accuracy: 0.6902\n",
      "402/402 [==============================] - 1s 2ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         119     0.8693    0.4290    0.5745      1070\n",
      "         120     0.3403    0.6633    0.4498       196\n",
      "         125     0.7273    0.8421    0.7805       532\n",
      "         134     0.8889    0.4211    0.5714        19\n",
      "         190     0.7054    0.8500    0.7710       200\n",
      "          20     0.5226    0.2284    0.3179       810\n",
      "         200     0.5746    0.6136    0.5934       590\n",
      "         203     0.3077    0.5926    0.4051        27\n",
      "          22     0.7831    0.8919    0.8339       518\n",
      "         269     0.3071    0.3679    0.3348       106\n",
      "         276     0.2553    0.3750    0.3038        64\n",
      "         287     0.4712    0.6035    0.5292       285\n",
      "         295     0.5600    0.6914    0.6188        81\n",
      "         306     0.2632    0.1064    0.1515        94\n",
      "         312     0.1774    0.2619    0.2115        42\n",
      "         319     0.3939    0.5098    0.4444        51\n",
      "         326     0.1613    0.1613    0.1613        31\n",
      "         327     0.2391    0.6286    0.3465        35\n",
      "         345     0.2500    0.1538    0.1905        26\n",
      "         347     0.2830    0.6250    0.3896        24\n",
      "         352     0.5767    0.9051    0.7045       453\n",
      "         362     0.6957    0.7869    0.7385       122\n",
      "         400     0.2767    0.6377    0.3860       138\n",
      "         401     0.6286    0.4231    0.5057        52\n",
      "         415     0.6471    0.7857    0.7097        42\n",
      "         416     0.9082    0.8523    0.8794       325\n",
      "         426     0.8235    0.3333    0.4746        42\n",
      "         427     0.5079    0.7273    0.5981        44\n",
      "         434     0.6556    0.8144    0.7264       194\n",
      "         476     0.5372    0.8744    0.6655       223\n",
      "         502     0.3370    0.8505    0.4828       107\n",
      "         522     0.4270    0.4222    0.4246        90\n",
      "         532     0.3662    0.5909    0.4522        44\n",
      "          59     0.5238    0.8073    0.6354       109\n",
      "         601     0.6914    0.7887    0.7368        71\n",
      "         611     0.5283    0.9130    0.6693        92\n",
      "         617     0.4259    0.6053    0.5000        38\n",
      "         639     0.4688    0.5357    0.5000        28\n",
      "         668     0.0000    0.0000    0.0000        45\n",
      "         732     0.1727    0.2449    0.2025        98\n",
      "          74     0.1418    0.2676    0.1854        71\n",
      "         755     0.1500    0.2143    0.1765        28\n",
      "          77     0.6133    0.3108    0.4126       148\n",
      "         770     0.2807    0.2712    0.2759        59\n",
      "         772     0.5556    0.2941    0.3846        34\n",
      "          78     0.6343    0.6622    0.6479       296\n",
      "         787     0.6143    0.6674    0.6397       890\n",
      "          79     0.9870    0.6742    0.8012      2256\n",
      "         798     0.6744    0.6744    0.6744       129\n",
      "         835     0.3846    0.7317    0.5042        41\n",
      "         843     0.5909    0.7647    0.6667        34\n",
      "         862     0.5472    0.6318    0.5865       220\n",
      "         863     0.2044    0.2373    0.2196       118\n",
      "          89     0.9888    0.8339    0.9048       957\n",
      "         908     0.4444    0.5000    0.4706        24\n",
      "         918     0.9189    0.7556    0.8293        90\n",
      "          94     0.4224    0.5685    0.4847       292\n",
      "\n",
      "    accuracy                         0.6350     12845\n",
      "   macro avg     0.4988    0.5610    0.5059     12845\n",
      "weighted avg     0.6923    0.6350    0.6390     12845\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['label_encoder_train_terms.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import joblib\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class F1ScoreCallback(Callback):\n",
    "    def __init__(self, X_val, y_val):\n",
    "        super(F1ScoreCallback, self).__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.best_f1 = 0.0\n",
    "        self.best_model = None\n",
    "        self.f1_scores = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_val_pred = np.argmax(self.model.predict(self.X_val), axis=1)\n",
    "        f1 = f1_score(self.y_val, y_val_pred, average='weighted')\n",
    "        self.f1_scores.append(f1)\n",
    "        \n",
    "\n",
    "        if f1 > self.best_f1:\n",
    "            self.best_f1 = f1\n",
    "            self.best_model = self.model\n",
    "            print(f\"Epoch {epoch + 1} - F1 Score: {f1:.4f}\")\n",
    "            print(\"Saved best model\")\n",
    "            print(self.f1_scores)\n",
    "\n",
    "with open('train_bert_comp.pickle', 'rb') as f1:\n",
    "    balanced = pickle.load(f1)\n",
    "\n",
    "with open('bert_comparison_test.pickle', 'rb') as f2:\n",
    "    unbalanced = pickle.load(f2)\n",
    "\n",
    "train = np.array([item['cve_terms_bert_mean'].tolist() for item in balanced if item['cwe'] != 'None'])\n",
    "\n",
    "test = np.array([item['cwe'] for item in balanced if item['cwe'] != 'None'])\n",
    "np.random.seed(42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(train,test,test_size=0.1,random_state=42)\n",
    "\n",
    "X_test = np.array([item['cve_terms_bert_mean'].tolist() for item in unbalanced if item['cwe'] != 'None'])\n",
    "y_test = np.array([item['cwe'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "\n",
    "label_encoder_train = LabelEncoder()\n",
    "y_train_encoded = label_encoder_train.fit_transform(y_train)\n",
    "label_encoder_test = LabelEncoder()\n",
    "y_test_encoded = label_encoder_test.fit_transform(y_test)\n",
    "\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = len(np.unique(y_train))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "f1_callback = F1ScoreCallback(X_val, label_encoder_train.transform(y_val))\n",
    "\n",
    "history = model.fit(X_train, y_train_encoded, epochs=40, batch_size=32, validation_data=(X_val, label_encoder_train.transform(y_val)), verbose=1, callbacks=[f1_callback])\n",
    "\n",
    "best_model = f1_callback.best_model\n",
    "\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model, 'best_model_terms.joblib')\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_probs = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "y_pred_original = label_encoder_train.inverse_transform(y_pred)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_original, digits=4))\n",
    "\n",
    "joblib.dump(label_encoder_train, 'label_encoder_train_terms.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference for CVE terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 [==============================] - 1s 2ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         119     0.8693    0.4290    0.5745      1070\n",
      "         120     0.3403    0.6633    0.4498       196\n",
      "         125     0.7273    0.8421    0.7805       532\n",
      "         134     0.8889    0.4211    0.5714        19\n",
      "         190     0.7054    0.8500    0.7710       200\n",
      "          20     0.5226    0.2284    0.3179       810\n",
      "         200     0.5746    0.6136    0.5934       590\n",
      "         203     0.3077    0.5926    0.4051        27\n",
      "          22     0.7831    0.8919    0.8339       518\n",
      "         269     0.3071    0.3679    0.3348       106\n",
      "         276     0.2553    0.3750    0.3038        64\n",
      "         287     0.4712    0.6035    0.5292       285\n",
      "         295     0.5600    0.6914    0.6188        81\n",
      "         306     0.2632    0.1064    0.1515        94\n",
      "         312     0.1774    0.2619    0.2115        42\n",
      "         319     0.3939    0.5098    0.4444        51\n",
      "         326     0.1613    0.1613    0.1613        31\n",
      "         327     0.2391    0.6286    0.3465        35\n",
      "         345     0.2500    0.1538    0.1905        26\n",
      "         347     0.2830    0.6250    0.3896        24\n",
      "         352     0.5767    0.9051    0.7045       453\n",
      "         362     0.6957    0.7869    0.7385       122\n",
      "         400     0.2767    0.6377    0.3860       138\n",
      "         401     0.6286    0.4231    0.5057        52\n",
      "         415     0.6471    0.7857    0.7097        42\n",
      "         416     0.9082    0.8523    0.8794       325\n",
      "         426     0.8235    0.3333    0.4746        42\n",
      "         427     0.5079    0.7273    0.5981        44\n",
      "         434     0.6556    0.8144    0.7264       194\n",
      "         476     0.5372    0.8744    0.6655       223\n",
      "         502     0.3370    0.8505    0.4828       107\n",
      "         522     0.4270    0.4222    0.4246        90\n",
      "         532     0.3662    0.5909    0.4522        44\n",
      "          59     0.5238    0.8073    0.6354       109\n",
      "         601     0.6914    0.7887    0.7368        71\n",
      "         611     0.5283    0.9130    0.6693        92\n",
      "         617     0.4259    0.6053    0.5000        38\n",
      "         639     0.4688    0.5357    0.5000        28\n",
      "         668     0.0000    0.0000    0.0000        45\n",
      "         732     0.1727    0.2449    0.2025        98\n",
      "          74     0.1418    0.2676    0.1854        71\n",
      "         755     0.1500    0.2143    0.1765        28\n",
      "          77     0.6133    0.3108    0.4126       148\n",
      "         770     0.2807    0.2712    0.2759        59\n",
      "         772     0.5556    0.2941    0.3846        34\n",
      "          78     0.6343    0.6622    0.6479       296\n",
      "         787     0.6143    0.6674    0.6397       890\n",
      "          79     0.9870    0.6742    0.8012      2256\n",
      "         798     0.6744    0.6744    0.6744       129\n",
      "         835     0.3846    0.7317    0.5042        41\n",
      "         843     0.5909    0.7647    0.6667        34\n",
      "         862     0.5472    0.6318    0.5865       220\n",
      "         863     0.2044    0.2373    0.2196       118\n",
      "          89     0.9888    0.8339    0.9048       957\n",
      "         908     0.4444    0.5000    0.4706        24\n",
      "         918     0.9189    0.7556    0.8293        90\n",
      "          94     0.4224    0.5685    0.4847       292\n",
      "\n",
      "    accuracy                         0.6350     12845\n",
      "   macro avg     0.4988    0.5610    0.5059     12845\n",
      "weighted avg     0.6923    0.6350    0.6390     12845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Save the best model\n",
    "with open('bert_comparison_test.pickle', 'rb') as f2:\n",
    "    unbalanced = pickle.load(f2)\n",
    "\n",
    "X_test = np.array([item['cve_terms_bert_mean'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "y_test = np.array([item['cwe'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "\n",
    "best_model=joblib.load('best_model_terms.joblib')\n",
    "label_encoder_train=joblib.load('label_encoder_train_terms.joblib')\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_probs = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "y_pred_original = label_encoder_train.inverse_transform(y_pred)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_original, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

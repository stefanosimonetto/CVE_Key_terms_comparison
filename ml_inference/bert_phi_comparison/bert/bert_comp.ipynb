{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for BERT based on CVE descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 2.1493 - accurac\n",
      "Epoch 1 - F1 Score: 0.5050\n",
      "Saved best model\n",
      "[0.5049995175544824]\n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 2.1451 - accuracy: 0.4420 - val_loss: 1.6952 - val_accuracy: 0.5397\n",
      "Epoch 2/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.5999 - ac\n",
      "Epoch 2 - F1 Score: 0.5541\n",
      "Saved best model\n",
      "[0.5049995175544824, 0.5541061113098998]\n",
      "2036/2036 [==============================] - 5s 2ms/step - loss: 1.5995 - accuracy: 0.5660 - val_loss: 1.5511 - val_accuracy: 0.5759\n",
      "Epoch 3/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.4550 - accura\n",
      "Epoch 3 - F1 Score: 0.5922\n",
      "Saved best model\n",
      "[0.5049995175544824, 0.5541061113098998, 0.5921520336822977]\n",
      "2036/2036 [==============================] - 5s 3ms/step - loss: 1.4553 - accuracy: 0.5989 - val_loss: 1.4231 - val_accuracy: 0.6120\n",
      "Epoch 4/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.3681 \n",
      "Epoch 4 - F1 Score: 0.6042\n",
      "Saved best model\n",
      "[0.5049995175544824, 0.5541061113098998, 0.5921520336822977, 0.6042119934816004]\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 1.3678 - accuracy: 0.6253 - val_loss: 1.3767 - val_accuracy: 0.6222\n",
      "Epoch 5/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.3115 \n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 1.3109 - accuracy: 0.6359 - val_loss: 1.3506 - val_accuracy: 0.6235\n",
      "Epoch 6/40\n",
      "227/227 [==============================] - 1s 2ms/step loss: 1.264\n",
      "Epoch 6 - F1 Score: 0.6160\n",
      "Saved best model\n",
      "[0.5049995175544824, 0.5541061113098998, 0.5921520336822977, 0.6042119934816004, 0.6038051709773709, 0.6159929895304281]\n",
      "2036/2036 [==============================] - 9s 5ms/step - loss: 1.2641 - accuracy: 0.6482 - val_loss: 1.3398 - val_accuracy: 0.6323\n",
      "Epoch 7/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.2296 \n",
      "Epoch 7 - F1 Score: 0.6300\n",
      "Saved best model\n",
      "[0.5049995175544824, 0.5541061113098998, 0.5921520336822977, 0.6042119934816004, 0.6038051709773709, 0.6159929895304281, 0.6300056787976503]\n",
      "2036/2036 [==============================] - 9s 4ms/step - loss: 1.2294 - accuracy: 0.6548 - val_loss: 1.2897 - val_accuracy: 0.6446\n",
      "Epoch 8/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.1987 - accu\n",
      "2036/2036 [==============================] - 9s 4ms/step - loss: 1.1991 - accuracy: 0.6624 - val_loss: 1.2965 - val_accuracy: 0.6377\n",
      "Epoch 9/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.170\n",
      "Epoch 9 - F1 Score: 0.6454\n",
      "Saved best model\n",
      "[0.5049995175544824, 0.5541061113098998, 0.5921520336822977, 0.6042119934816004, 0.6038051709773709, 0.6159929895304281, 0.6300056787976503, 0.619018540414728, 0.6454283836508902]\n",
      "2036/2036 [==============================] - 9s 5ms/step - loss: 1.1712 - accuracy: 0.6711 - val_loss: 1.2274 - val_accuracy: 0.6561\n",
      "Epoch 10/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.1431 - \n",
      "2036/2036 [==============================] - 9s 4ms/step - loss: 1.1433 - accuracy: 0.6753 - val_loss: 1.2823 - val_accuracy: 0.6465\n",
      "Epoch 11/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.124\n",
      "2036/2036 [==============================] - 9s 5ms/step - loss: 1.1249 - accuracy: 0.6812 - val_loss: 1.3101 - val_accuracy: 0.6452\n",
      "Epoch 12/40\n",
      "227/227 [==============================] - 1s 2ms/step loss: 1.109\n",
      "2036/2036 [==============================] - 9s 4ms/step - loss: 1.1101 - accuracy: 0.6837 - val_loss: 1.2564 - val_accuracy: 0.6548\n",
      "Epoch 13/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.0892 - \n",
      "Epoch 13 - F1 Score: 0.6492\n",
      "Saved best model\n",
      "[0.5049995175544824, 0.5541061113098998, 0.5921520336822977, 0.6042119934816004, 0.6038051709773709, 0.6159929895304281, 0.6300056787976503, 0.619018540414728, 0.6454283836508902, 0.6307155503961062, 0.6320679016177013, 0.6452238519086195, 0.6491978189532143]\n",
      "2036/2036 [==============================] - 9s 4ms/step - loss: 1.0895 - accuracy: 0.6887 - val_loss: 1.2396 - val_accuracy: 0.6609\n",
      "Epoch 14/40\n",
      "227/227 [==============================] - 1s 3ms/step loss:\n",
      "Epoch 14 - F1 Score: 0.6508\n",
      "Saved best model\n",
      "[0.5049995175544824, 0.5541061113098998, 0.5921520336822977, 0.6042119934816004, 0.6038051709773709, 0.6159929895304281, 0.6300056787976503, 0.619018540414728, 0.6454283836508902, 0.6307155503961062, 0.6320679016177013, 0.6452238519086195, 0.6491978189532143, 0.6507507191164259]\n",
      "2036/2036 [==============================] - 10s 5ms/step - loss: 1.0748 - accuracy: 0.6932 - val_loss: 1.2548 - val_accuracy: 0.6599\n",
      "Epoch 15/40\n",
      "227/227 [==============================] - 1s 3ms/step loss: 1.\n",
      "2036/2036 [==============================] - 12s 6ms/step - loss: 1.0574 - accuracy: 0.6973 - val_loss: 1.2504 - val_accuracy: 0.6561\n",
      "Epoch 16/40\n",
      "227/227 [==============================] - 1s 3ms/step loss: \n",
      "Epoch 16 - F1 Score: 0.6543\n",
      "Saved best model\n",
      "[0.5049995175544824, 0.5541061113098998, 0.5921520336822977, 0.6042119934816004, 0.6038051709773709, 0.6159929895304281, 0.6300056787976503, 0.619018540414728, 0.6454283836508902, 0.6307155503961062, 0.6320679016177013, 0.6452238519086195, 0.6491978189532143, 0.6507507191164259, 0.6401680396384071, 0.6543050909927308]\n",
      "2036/2036 [==============================] - 12s 6ms/step - loss: 1.0427 - accuracy: 0.7004 - val_loss: 1.2152 - val_accuracy: 0.6659\n",
      "Epoch 17/40\n",
      "227/227 [==============================] - 1s 3ms/step loss:\n",
      "2036/2036 [==============================] - 13s 6ms/step - loss: 1.0297 - accuracy: 0.7025 - val_loss: 1.2784 - val_accuracy: 0.6487\n",
      "Epoch 18/40\n",
      "227/227 [==============================] - 1s 3ms/step los\n",
      "Epoch 18 - F1 Score: 0.6572\n",
      "Saved best model\n",
      "[0.5049995175544824, 0.5541061113098998, 0.5921520336822977, 0.6042119934816004, 0.6038051709773709, 0.6159929895304281, 0.6300056787976503, 0.619018540414728, 0.6454283836508902, 0.6307155503961062, 0.6320679016177013, 0.6452238519086195, 0.6491978189532143, 0.6507507191164259, 0.6401680396384071, 0.6543050909927308, 0.6418814637071285, 0.6571551375361614]\n",
      "2036/2036 [==============================] - 13s 6ms/step - loss: 1.0223 - accuracy: 0.7040 - val_loss: 1.2485 - val_accuracy: 0.6657\n",
      "Epoch 19/40\n",
      "227/227 [==============================] - 1s 3ms/step loss: 1\n",
      "2036/2036 [==============================] - 13s 6ms/step - loss: 1.0074 - accuracy: 0.7101 - val_loss: 1.2738 - val_accuracy: 0.6503\n",
      "Epoch 20/40\n",
      "227/227 [==============================] - 1s 3ms/step loss:\n",
      "2036/2036 [==============================] - 13s 6ms/step - loss: 0.9950 - accuracy: 0.7106 - val_loss: 1.2656 - val_accuracy: 0.6606\n",
      "Epoch 21/40\n",
      "227/227 [==============================] - 1s 4ms/step\n",
      "2036/2036 [==============================] - 13s 6ms/step - loss: 0.9861 - accuracy: 0.7138 - val_loss: 1.2450 - val_accuracy: 0.6615\n",
      "Epoch 22/40\n",
      "227/227 [==============================] - 1s 3ms/step loss:\n",
      "2036/2036 [==============================] - 12s 6ms/step - loss: 0.9758 - accuracy: 0.7166 - val_loss: 1.2491 - val_accuracy: 0.6613\n",
      "Epoch 23/40\n",
      "227/227 [==============================] - 1s 3ms/step loss: 0.\n",
      "Epoch 23 - F1 Score: 0.6628\n",
      "Saved best model\n",
      "[0.5049995175544824, 0.5541061113098998, 0.5921520336822977, 0.6042119934816004, 0.6038051709773709, 0.6159929895304281, 0.6300056787976503, 0.619018540414728, 0.6454283836508902, 0.6307155503961062, 0.6320679016177013, 0.6452238519086195, 0.6491978189532143, 0.6507507191164259, 0.6401680396384071, 0.6543050909927308, 0.6418814637071285, 0.6571551375361614, 0.6454807396996465, 0.6456414945950708, 0.6510889509897813, 0.653598594582956, 0.6628387236809349]\n",
      "2036/2036 [==============================] - 11s 5ms/step - loss: 0.9674 - accuracy: 0.7167 - val_loss: 1.2229 - val_accuracy: 0.6689\n",
      "Epoch 24/40\n",
      "227/227 [==============================] - 1s 3ms/step loss: 0.9\n",
      "2036/2036 [==============================] - 11s 6ms/step - loss: 0.9537 - accuracy: 0.7220 - val_loss: 1.2332 - val_accuracy: 0.6680\n",
      "Epoch 25/40\n",
      "227/227 [==============================] - 1s 3ms/step loss: 0\n",
      "2036/2036 [==============================] - 11s 6ms/step - loss: 0.9501 - accuracy: 0.7232 - val_loss: 1.2554 - val_accuracy: 0.6655\n",
      "Epoch 26/40\n",
      "227/227 [==============================] - 1s 3ms/step loss:\n",
      "2036/2036 [==============================] - 11s 5ms/step - loss: 0.9365 - accuracy: 0.7262 - val_loss: 1.2712 - val_accuracy: 0.6631\n",
      "Epoch 27/40\n",
      "227/227 [==============================] - 1s 3ms/step loss: 0\n",
      "Epoch 27 - F1 Score: 0.6629\n",
      "Saved best model\n",
      "[0.5049995175544824, 0.5541061113098998, 0.5921520336822977, 0.6042119934816004, 0.6038051709773709, 0.6159929895304281, 0.6300056787976503, 0.619018540414728, 0.6454283836508902, 0.6307155503961062, 0.6320679016177013, 0.6452238519086195, 0.6491978189532143, 0.6507507191164259, 0.6401680396384071, 0.6543050909927308, 0.6418814637071285, 0.6571551375361614, 0.6454807396996465, 0.6456414945950708, 0.6510889509897813, 0.653598594582956, 0.6628387236809349, 0.6601027733479116, 0.6586974981383844, 0.652962881299208, 0.6628654556057788]\n",
      "2036/2036 [==============================] - 11s 6ms/step - loss: 0.9302 - accuracy: 0.7276 - val_loss: 1.2459 - val_accuracy: 0.6645\n",
      "Epoch 28/40\n",
      "227/227 [==============================] - 1s 3ms/step loss\n",
      "2036/2036 [==============================] - 12s 6ms/step - loss: 0.9206 - accuracy: 0.7284 - val_loss: 1.2438 - val_accuracy: 0.6696\n",
      "Epoch 29/40\n",
      "227/227 [==============================] - 1s 3ms/step loss: \n",
      "2036/2036 [==============================] - 13s 6ms/step - loss: 0.9108 - accuracy: 0.7318 - val_loss: 1.2460 - val_accuracy: 0.6685\n",
      "Epoch 30/40\n",
      "227/227 [==============================] - 1s 3ms/step loss: 0\n",
      "2036/2036 [==============================] - 12s 6ms/step - loss: 0.9069 - accuracy: 0.7331 - val_loss: 1.2677 - val_accuracy: 0.6657\n",
      "Epoch 31/40\n",
      "227/227 [==============================] - 1s 3ms/step loss: \n",
      "2036/2036 [==============================] - 12s 6ms/step - loss: 0.8984 - accuracy: 0.7361 - val_loss: 1.2430 - val_accuracy: 0.6686\n",
      "Epoch 32/40\n",
      "227/227 [==============================] - 1s 3ms/step loss: \n",
      "2036/2036 [==============================] - 12s 6ms/step - loss: 0.8914 - accuracy: 0.7372 - val_loss: 1.2529 - val_accuracy: 0.6669\n",
      "Epoch 33/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 0.8810 \n",
      "Epoch 33 - F1 Score: 0.6694\n",
      "Saved best model\n",
      "[0.5049995175544824, 0.5541061113098998, 0.5921520336822977, 0.6042119934816004, 0.6038051709773709, 0.6159929895304281, 0.6300056787976503, 0.619018540414728, 0.6454283836508902, 0.6307155503961062, 0.6320679016177013, 0.6452238519086195, 0.6491978189532143, 0.6507507191164259, 0.6401680396384071, 0.6543050909927308, 0.6418814637071285, 0.6571551375361614, 0.6454807396996465, 0.6456414945950708, 0.6510889509897813, 0.653598594582956, 0.6628387236809349, 0.6601027733479116, 0.6586974981383844, 0.652962881299208, 0.6628654556057788, 0.6614102846907827, 0.6562566365972547, 0.6510925589048018, 0.6623040490948228, 0.6575236165070469, 0.6693884740198335]\n",
      "2036/2036 [==============================] - 8s 4ms/step - loss: 0.8809 - accuracy: 0.7404 - val_loss: 1.2465 - val_accuracy: 0.6732\n",
      "Epoch 34/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 0.8804 - ac\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 0.8804 - accuracy: 0.7395 - val_loss: 1.2755 - val_accuracy: 0.6653\n",
      "Epoch 35/40\n",
      "227/227 [==============================] - 1s 2ms/step loss: 0.8\n",
      "2036/2036 [==============================] - 7s 4ms/step - loss: 0.8723 - accuracy: 0.7407 - val_loss: 1.2485 - val_accuracy: 0.6688\n",
      "Epoch 36/40\n",
      "227/227 [==============================] - 1s 3ms/step loss: 0\n",
      "2036/2036 [==============================] - 8s 4ms/step - loss: 0.8675 - accuracy: 0.7408 - val_loss: 1.2680 - val_accuracy: 0.6715\n",
      "Epoch 37/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 0.856\n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 0.8563 - accuracy: 0.7454 - val_loss: 1.2708 - val_accuracy: 0.6696\n",
      "Epoch 38/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 0.8527 \n",
      "Epoch 38 - F1 Score: 0.6696\n",
      "Saved best model\n",
      "[0.5049995175544824, 0.5541061113098998, 0.5921520336822977, 0.6042119934816004, 0.6038051709773709, 0.6159929895304281, 0.6300056787976503, 0.619018540414728, 0.6454283836508902, 0.6307155503961062, 0.6320679016177013, 0.6452238519086195, 0.6491978189532143, 0.6507507191164259, 0.6401680396384071, 0.6543050909927308, 0.6418814637071285, 0.6571551375361614, 0.6454807396996465, 0.6456414945950708, 0.6510889509897813, 0.653598594582956, 0.6628387236809349, 0.6601027733479116, 0.6586974981383844, 0.652962881299208, 0.6628654556057788, 0.6614102846907827, 0.6562566365972547, 0.6510925589048018, 0.6623040490948228, 0.6575236165070469, 0.6693884740198335, 0.6576895931469644, 0.6625290244278044, 0.6678920273753377, 0.6654042605303472, 0.6695507942425568]\n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 0.8526 - accuracy: 0.7455 - val_loss: 1.2385 - val_accuracy: 0.6776\n",
      "Epoch 39/40\n",
      "227/227 [==============================] - 1s 2ms/step loss: 0.8\n",
      "2036/2036 [==============================] - 7s 4ms/step - loss: 0.8459 - accuracy: 0.7478 - val_loss: 1.2940 - val_accuracy: 0.6663\n",
      "Epoch 40/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 0.8416 \n",
      "Epoch 40 - F1 Score: 0.6703\n",
      "Saved best model\n",
      "[0.5049995175544824, 0.5541061113098998, 0.5921520336822977, 0.6042119934816004, 0.6038051709773709, 0.6159929895304281, 0.6300056787976503, 0.619018540414728, 0.6454283836508902, 0.6307155503961062, 0.6320679016177013, 0.6452238519086195, 0.6491978189532143, 0.6507507191164259, 0.6401680396384071, 0.6543050909927308, 0.6418814637071285, 0.6571551375361614, 0.6454807396996465, 0.6456414945950708, 0.6510889509897813, 0.653598594582956, 0.6628387236809349, 0.6601027733479116, 0.6586974981383844, 0.652962881299208, 0.6628654556057788, 0.6614102846907827, 0.6562566365972547, 0.6510925589048018, 0.6623040490948228, 0.6575236165070469, 0.6693884740198335, 0.6576895931469644, 0.6625290244278044, 0.6678920273753377, 0.6654042605303472, 0.6695507942425568, 0.6565421985320274, 0.6702629753487975]\n",
      "2036/2036 [==============================] - 9s 4ms/step - loss: 0.8421 - accuracy: 0.7483 - val_loss: 1.2712 - val_accuracy: 0.6729\n",
      "402/402 [==============================] - 1s 2ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         119     0.9229    0.3355    0.4921      1070\n",
      "         120     0.4480    0.6378    0.5263       196\n",
      "         125     0.6327    0.8158    0.7126       532\n",
      "         134     0.2273    0.5263    0.3175        19\n",
      "         190     0.8118    0.7550    0.7824       200\n",
      "          20     0.4286    0.3407    0.3796       810\n",
      "         200     0.6905    0.5068    0.5846       590\n",
      "         203     0.2836    0.7037    0.4043        27\n",
      "          22     0.7953    0.8552    0.8242       518\n",
      "         269     0.2402    0.4057    0.3018       106\n",
      "         276     0.2165    0.3281    0.2609        64\n",
      "         287     0.4671    0.5474    0.5040       285\n",
      "         295     0.5833    0.6049    0.5939        81\n",
      "         306     0.2596    0.2872    0.2727        94\n",
      "         312     0.1667    0.0952    0.1212        42\n",
      "         319     0.4800    0.4706    0.4752        51\n",
      "         326     0.2500    0.0968    0.1395        31\n",
      "         327     0.3000    0.5143    0.3789        35\n",
      "         345     0.2308    0.2308    0.2308        26\n",
      "         347     0.4643    0.5417    0.5000        24\n",
      "         352     0.4603    0.8830    0.6051       453\n",
      "         362     0.4502    0.7787    0.5706       122\n",
      "         400     0.1826    0.6377    0.2839       138\n",
      "         401     0.4667    0.4038    0.4330        52\n",
      "         415     0.3659    0.3571    0.3614        42\n",
      "         416     0.8245    0.8092    0.8168       325\n",
      "         426     0.5500    0.5238    0.5366        42\n",
      "         427     0.4828    0.6364    0.5490        44\n",
      "         434     0.4550    0.8608    0.5954       194\n",
      "         476     0.7347    0.8072    0.7692       223\n",
      "         502     0.3737    0.6916    0.4852       107\n",
      "         522     0.4096    0.3778    0.3931        90\n",
      "         532     0.4426    0.6136    0.5143        44\n",
      "          59     0.5682    0.6881    0.6224       109\n",
      "         601     0.6538    0.7183    0.6846        71\n",
      "         611     0.5763    0.7391    0.6476        92\n",
      "         617     0.5000    0.6053    0.5476        38\n",
      "         639     0.2083    0.3571    0.2632        28\n",
      "         668     0.0612    0.0667    0.0638        45\n",
      "         732     0.2179    0.1735    0.1932        98\n",
      "          74     0.0675    0.3803    0.1146        71\n",
      "         755     0.0952    0.0714    0.0816        28\n",
      "          77     0.4343    0.5135    0.4706       148\n",
      "         770     0.1296    0.1186    0.1239        59\n",
      "         772     0.4242    0.4118    0.4179        34\n",
      "          78     0.5172    0.6622    0.5807       296\n",
      "         787     0.6270    0.6045    0.6156       890\n",
      "          79     0.9893    0.4902    0.6556      2256\n",
      "         798     0.6441    0.5891    0.6154       129\n",
      "         835     0.2680    0.6341    0.3768        41\n",
      "         843     0.4898    0.7059    0.5783        34\n",
      "         862     0.4910    0.6182    0.5473       220\n",
      "         863     0.2791    0.2034    0.2353       118\n",
      "          89     0.9940    0.6907    0.8150       957\n",
      "         908     0.4583    0.4583    0.4583        24\n",
      "         918     0.2677    0.7556    0.3953        90\n",
      "          94     0.3834    0.5068    0.4366       292\n",
      "\n",
      "    accuracy                         0.5668     12845\n",
      "   macro avg     0.4464    0.5218    0.4607     12845\n",
      "weighted avg     0.6734    0.5668    0.5812     12845\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['label_encoder_train_descr.joblib']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import joblib\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class F1ScoreCallback(Callback):\n",
    "    def __init__(self, X_val, y_val):\n",
    "        super(F1ScoreCallback, self).__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.best_f1 = 0.0\n",
    "        self.best_model = None\n",
    "        self.f1_scores = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_val_pred = np.argmax(self.model.predict(self.X_val), axis=1)\n",
    "        f1 = f1_score(self.y_val, y_val_pred, average='weighted')\n",
    "        self.f1_scores.append(f1)\n",
    "        \n",
    "\n",
    "        if f1 > self.best_f1:\n",
    "            self.best_f1 = f1\n",
    "            self.best_model = self.model\n",
    "            print(f\"Epoch {epoch + 1} - F1 Score: {f1:.4f}\")\n",
    "            print(\"Saved best model\")\n",
    "            print(self.f1_scores)\n",
    "\n",
    "with open('train_bert_comp.pickle', 'rb') as f1:\n",
    "    balanced = pickle.load(f1)\n",
    "\n",
    "with open('bert_comparison_test.pickle', 'rb') as f2:\n",
    "    unbalanced = pickle.load(f2)\n",
    "\n",
    "train = np.array([item['cve_description_bert_mean'].tolist() for item in balanced if item['cwe'] != 'None'])\n",
    "\n",
    "test = np.array([item['cwe'] for item in balanced if item['cwe'] != 'None'])\n",
    "np.random.seed(42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(train,test,test_size=0.1,random_state=42)\n",
    "\n",
    "X_test = np.array([item['cve_description_bert_mean'].tolist() for item in unbalanced if item['cwe'] != 'None'])\n",
    "y_test = np.array([item['cwe'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "\n",
    "label_encoder_train = LabelEncoder()\n",
    "y_train_encoded = label_encoder_train.fit_transform(y_train)\n",
    "label_encoder_test = LabelEncoder()\n",
    "y_test_encoded = label_encoder_test.fit_transform(y_test)\n",
    "\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = len(np.unique(y_train))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "f1_callback = F1ScoreCallback(X_val, label_encoder_train.transform(y_val))\n",
    "\n",
    "history = model.fit(X_train, y_train_encoded, epochs=40, batch_size=32, validation_data=(X_val, label_encoder_train.transform(y_val)), verbose=1, callbacks=[f1_callback])\n",
    "\n",
    "best_model = f1_callback.best_model\n",
    "\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model, 'best_model_descr.joblib')\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_probs = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "y_pred_original = label_encoder_train.inverse_transform(y_pred)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_original, digits=4))\n",
    "\n",
    "joblib.dump(label_encoder_train, 'label_encoder_train_descr.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference for CVE description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 [==============================] - 1s 1ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         119     0.8668    0.4318    0.5764      1070\n",
      "         120     0.4715    0.6327    0.5403       196\n",
      "         125     0.6442    0.8271    0.7243       532\n",
      "         134     0.3793    0.5789    0.4583        19\n",
      "         190     0.6996    0.8150    0.7529       200\n",
      "          20     0.4914    0.3160    0.3847       810\n",
      "         200     0.7224    0.4763    0.5741       590\n",
      "         203     0.4375    0.5185    0.4746        27\n",
      "          22     0.8185    0.8359    0.8271       518\n",
      "         269     0.1909    0.4340    0.2651       106\n",
      "         276     0.2143    0.1875    0.2000        64\n",
      "         287     0.3859    0.6526    0.4850       285\n",
      "         295     0.4574    0.7284    0.5619        81\n",
      "         306     0.1643    0.2447    0.1966        94\n",
      "         312     0.2273    0.2381    0.2326        42\n",
      "         319     0.6000    0.2941    0.3947        51\n",
      "         326     0.1935    0.1935    0.1935        31\n",
      "         327     0.3611    0.3714    0.3662        35\n",
      "         345     0.1081    0.1538    0.1270        26\n",
      "         347     0.2917    0.5833    0.3889        24\n",
      "         352     0.5815    0.8587    0.6934       453\n",
      "         362     0.5556    0.6557    0.6015       122\n",
      "         400     0.3594    0.3333    0.3459       138\n",
      "         401     0.5283    0.5385    0.5333        52\n",
      "         415     0.4583    0.2619    0.3333        42\n",
      "         416     0.7699    0.8646    0.8145       325\n",
      "         426     0.4030    0.6429    0.4954        42\n",
      "         427     0.4918    0.6818    0.5714        44\n",
      "         434     0.4039    0.8557    0.5488       194\n",
      "         476     0.5601    0.8565    0.6773       223\n",
      "         502     0.5000    0.5234    0.5114       107\n",
      "         522     0.4737    0.4000    0.4337        90\n",
      "         532     0.4490    0.5000    0.4731        44\n",
      "          59     0.6293    0.6697    0.6489       109\n",
      "         601     0.3613    0.7887    0.4956        71\n",
      "         611     0.6286    0.7174    0.6701        92\n",
      "         617     0.4528    0.6316    0.5275        38\n",
      "         639     0.2273    0.3571    0.2778        28\n",
      "         668     0.0400    0.0222    0.0286        45\n",
      "         732     0.1688    0.2755    0.2093        98\n",
      "          74     0.1346    0.3944    0.2007        71\n",
      "         755     0.1096    0.2857    0.1584        28\n",
      "          77     0.4457    0.5270    0.4830       148\n",
      "         770     0.3478    0.2712    0.3048        59\n",
      "         772     0.7333    0.3235    0.4490        34\n",
      "          78     0.6026    0.6351    0.6184       296\n",
      "         787     0.6053    0.6685    0.6353       890\n",
      "          79     0.9911    0.5452    0.7035      2256\n",
      "         798     0.5915    0.6512    0.6199       129\n",
      "         835     0.4630    0.6098    0.5263        41\n",
      "         843     0.3544    0.8235    0.4956        34\n",
      "         862     0.5739    0.6000    0.5867       220\n",
      "         863     0.1536    0.3644    0.2161       118\n",
      "          89     0.9930    0.7388    0.8472       957\n",
      "         908     0.4091    0.3750    0.3913        24\n",
      "         918     0.7222    0.4333    0.5417        90\n",
      "          94     0.3069    0.6096    0.4083       292\n",
      "\n",
      "    accuracy                         0.5910     12845\n",
      "   macro avg     0.4615    0.5229    0.4702     12845\n",
      "weighted avg     0.6779    0.5910    0.6041     12845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Save the best model\n",
    "with open('bert_comparison_test.pickle', 'rb') as f2:\n",
    "    unbalanced = pickle.load(f2)\n",
    "\n",
    "X_test = np.array([item['cve_description_bert_mean'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "y_test = np.array([item['cwe'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "\n",
    "best_model=joblib.load('best_model_descr.joblib')\n",
    "label_encoder_train=joblib.load('label_encoder_train_descr.joblib')\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_probs = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "y_pred_original = label_encoder_train.inverse_transform(y_pred)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_original, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for BERT based on CVE terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "227/227 [==============================] - 0s 962us/steposs: 2.1700 - accurac\n",
      "Epoch 1 - F1 Score: 0.5107\n",
      "Saved best model\n",
      "[0.5107091911759324]\n",
      "2036/2036 [==============================] - 5s 2ms/step - loss: 2.1641 - accuracy: 0.4342 - val_loss: 1.6560 - val_accuracy: 0.5483\n",
      "Epoch 2/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.5771 - accura\n",
      "Epoch 2 - F1 Score: 0.5734\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414]\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 1.5765 - accuracy: 0.5662 - val_loss: 1.5280 - val_accuracy: 0.5935\n",
      "Epoch 3/40\n",
      "227/227 [==============================] - 0s 873us/steposs: 1.4415 - accuracy\n",
      "Epoch 3 - F1 Score: 0.5818\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929]\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 1.4414 - accuracy: 0.6021 - val_loss: 1.4117 - val_accuracy: 0.6132\n",
      "Epoch 4/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.3695 - accu\n",
      "Epoch 4 - F1 Score: 0.6093\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386]\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 1.3703 - accuracy: 0.6198 - val_loss: 1.3388 - val_accuracy: 0.6349\n",
      "Epoch 5/40\n",
      "227/227 [==============================] - 0s 938us/steposs: 1.3185 - accura\n",
      "Epoch 5 - F1 Score: 0.6216\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613]\n",
      "2036/2036 [==============================] - 5s 2ms/step - loss: 1.3184 - accuracy: 0.6330 - val_loss: 1.2973 - val_accuracy: 0.6421\n",
      "Epoch 6/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.2836 \n",
      "Epoch 6 - F1 Score: 0.6258\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384]\n",
      "2036/2036 [==============================] - 8s 4ms/step - loss: 1.2829 - accuracy: 0.6431 - val_loss: 1.3226 - val_accuracy: 0.6360\n",
      "Epoch 7/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.2489 - accura\n",
      "Epoch 7 - F1 Score: 0.6349\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384, 0.6348785953994661]\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 1.2485 - accuracy: 0.6521 - val_loss: 1.2642 - val_accuracy: 0.6532\n",
      "Epoch 8/40\n",
      "227/227 [==============================] - 0s 973us/steposs: 1.2229 - accura\n",
      "Epoch 8 - F1 Score: 0.6463\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384, 0.6348785953994661, 0.6462574309033058]\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 1.2226 - accuracy: 0.6576 - val_loss: 1.2567 - val_accuracy: 0.6561\n",
      "Epoch 9/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.2072 - accura\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 1.2069 - accuracy: 0.6623 - val_loss: 1.2677 - val_accuracy: 0.6500\n",
      "Epoch 10/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.1863 - ac\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 1.1865 - accuracy: 0.6661 - val_loss: 1.2617 - val_accuracy: 0.6547\n",
      "Epoch 11/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.1688 - ac\n",
      "Epoch 11 - F1 Score: 0.6484\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384, 0.6348785953994661, 0.6462574309033058, 0.6265552948336212, 0.6417515460048598, 0.6483553787627528]\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 1.1688 - accuracy: 0.6727 - val_loss: 1.2207 - val_accuracy: 0.6601\n",
      "Epoch 12/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.1604 \n",
      "Epoch 12 - F1 Score: 0.6514\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384, 0.6348785953994661, 0.6462574309033058, 0.6265552948336212, 0.6417515460048598, 0.6483553787627528, 0.6513983357221315]\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 1.1595 - accuracy: 0.6714 - val_loss: 1.1960 - val_accuracy: 0.6715\n",
      "Epoch 13/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.1454 - ac\n",
      "Epoch 13 - F1 Score: 0.6610\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384, 0.6348785953994661, 0.6462574309033058, 0.6265552948336212, 0.6417515460048598, 0.6483553787627528, 0.6513983357221315, 0.6610218959838702]\n",
      "2036/2036 [==============================] - 7s 4ms/step - loss: 1.1454 - accuracy: 0.6756 - val_loss: 1.1871 - val_accuracy: 0.6758\n",
      "Epoch 14/40\n",
      "227/227 [==============================] - 0s 809us/steposs: 1.1353 - accuracy\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 1.1348 - accuracy: 0.6784 - val_loss: 1.2019 - val_accuracy: 0.6698\n",
      "Epoch 15/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.1231 - \n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 1.1231 - accuracy: 0.6813 - val_loss: 1.1929 - val_accuracy: 0.6666\n",
      "Epoch 16/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.1121 - \n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 1.1122 - accuracy: 0.6846 - val_loss: 1.2080 - val_accuracy: 0.6696\n",
      "Epoch 17/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.1033 - ac\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 1.1033 - accuracy: 0.6870 - val_loss: 1.2092 - val_accuracy: 0.6619\n",
      "Epoch 18/40\n",
      "227/227 [==============================] - 0s 951us/steposs: 1.0951 - accura\n",
      "Epoch 18 - F1 Score: 0.6668\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384, 0.6348785953994661, 0.6462574309033058, 0.6265552948336212, 0.6417515460048598, 0.6483553787627528, 0.6513983357221315, 0.6610218959838702, 0.6590553504489519, 0.6598318937146613, 0.6535911232134137, 0.6515788929148386, 0.66683572272253]\n",
      "2036/2036 [==============================] - 5s 2ms/step - loss: 1.0953 - accuracy: 0.6883 - val_loss: 1.1763 - val_accuracy: 0.6771\n",
      "Epoch 19/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.0848 - accura\n",
      "Epoch 19 - F1 Score: 0.6697\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384, 0.6348785953994661, 0.6462574309033058, 0.6265552948336212, 0.6417515460048598, 0.6483553787627528, 0.6513983357221315, 0.6610218959838702, 0.6590553504489519, 0.6598318937146613, 0.6535911232134137, 0.6515788929148386, 0.66683572272253, 0.6696826282057595]\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 1.0849 - accuracy: 0.6906 - val_loss: 1.1663 - val_accuracy: 0.6821\n",
      "Epoch 20/40\n",
      "227/227 [==============================] - 0s 797us/steposs: 1.0779 - accuracy\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 1.0782 - accuracy: 0.6944 - val_loss: 1.1662 - val_accuracy: 0.6771\n",
      "Epoch 21/40\n",
      "227/227 [==============================] - 0s 961us/steposs: 1.0691 - accura\n",
      "Epoch 21 - F1 Score: 0.6725\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384, 0.6348785953994661, 0.6462574309033058, 0.6265552948336212, 0.6417515460048598, 0.6483553787627528, 0.6513983357221315, 0.6610218959838702, 0.6590553504489519, 0.6598318937146613, 0.6535911232134137, 0.6515788929148386, 0.66683572272253, 0.6696826282057595, 0.6684889703230777, 0.6724607067686212]\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 1.0690 - accuracy: 0.6956 - val_loss: 1.1597 - val_accuracy: 0.6797\n",
      "Epoch 22/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.0635 - accura\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 1.0639 - accuracy: 0.6966 - val_loss: 1.1562 - val_accuracy: 0.6838\n",
      "Epoch 23/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.0582 \n",
      "2036/2036 [==============================] - 5s 2ms/step - loss: 1.0584 - accuracy: 0.6984 - val_loss: 1.1734 - val_accuracy: 0.6785\n",
      "Epoch 24/40\n",
      "227/227 [==============================] - 1s 2ms/step loss: 1.051\n",
      "Epoch 24 - F1 Score: 0.6741\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384, 0.6348785953994661, 0.6462574309033058, 0.6265552948336212, 0.6417515460048598, 0.6483553787627528, 0.6513983357221315, 0.6610218959838702, 0.6590553504489519, 0.6598318937146613, 0.6535911232134137, 0.6515788929148386, 0.66683572272253, 0.6696826282057595, 0.6684889703230777, 0.6724607067686212, 0.6715293190072162, 0.667269965311054, 0.6741365769700944]\n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 1.0510 - accuracy: 0.6972 - val_loss: 1.1619 - val_accuracy: 0.6826\n",
      "Epoch 25/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.0447 - \n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 1.0444 - accuracy: 0.6988 - val_loss: 1.1565 - val_accuracy: 0.6861\n",
      "Epoch 26/40\n",
      "227/227 [==============================] - 1s 2ms/step loss: 1.041\n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 1.0412 - accuracy: 0.7012 - val_loss: 1.1684 - val_accuracy: 0.6801\n",
      "Epoch 27/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.0341 \n",
      "Epoch 27 - F1 Score: 0.6769\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384, 0.6348785953994661, 0.6462574309033058, 0.6265552948336212, 0.6417515460048598, 0.6483553787627528, 0.6513983357221315, 0.6610218959838702, 0.6590553504489519, 0.6598318937146613, 0.6535911232134137, 0.6515788929148386, 0.66683572272253, 0.6696826282057595, 0.6684889703230777, 0.6724607067686212, 0.6715293190072162, 0.667269965311054, 0.6741365769700944, 0.6700199544053506, 0.6678182995052413, 0.6768737172876371]\n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 1.0337 - accuracy: 0.7033 - val_loss: 1.1516 - val_accuracy: 0.6872\n",
      "Epoch 28/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.0296 - ac\n",
      "2036/2036 [==============================] - 7s 4ms/step - loss: 1.0293 - accuracy: 0.7041 - val_loss: 1.1538 - val_accuracy: 0.6815\n",
      "Epoch 29/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.0242 \n",
      "Epoch 29 - F1 Score: 0.6804\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384, 0.6348785953994661, 0.6462574309033058, 0.6265552948336212, 0.6417515460048598, 0.6483553787627528, 0.6513983357221315, 0.6610218959838702, 0.6590553504489519, 0.6598318937146613, 0.6535911232134137, 0.6515788929148386, 0.66683572272253, 0.6696826282057595, 0.6684889703230777, 0.6724607067686212, 0.6715293190072162, 0.667269965311054, 0.6741365769700944, 0.6700199544053506, 0.6678182995052413, 0.6768737172876371, 0.6667157880394359, 0.6803986176238958]\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 1.0242 - accuracy: 0.7070 - val_loss: 1.1335 - val_accuracy: 0.6910\n",
      "Epoch 30/40\n",
      "227/227 [==============================] - 0s 954us/steposs: 1.0216 - accura\n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 1.0208 - accuracy: 0.7056 - val_loss: 1.1449 - val_accuracy: 0.6843\n",
      "Epoch 31/40\n",
      "227/227 [==============================] - 0s 906us/steposs: 1.0127 - accura\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 1.0133 - accuracy: 0.7089 - val_loss: 1.1345 - val_accuracy: 0.6902\n",
      "Epoch 32/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 1.0075 - accura\n",
      "2036/2036 [==============================] - 4s 2ms/step - loss: 1.0075 - accuracy: 0.7085 - val_loss: 1.1568 - val_accuracy: 0.6844\n",
      "Epoch 33/40\n",
      "227/227 [==============================] - 1s 2ms/step loss: 1.004\n",
      "2036/2036 [==============================] - 7s 4ms/step - loss: 1.0048 - accuracy: 0.7101 - val_loss: 1.1677 - val_accuracy: 0.6812\n",
      "Epoch 34/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 1.0013 - \n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 1.0013 - accuracy: 0.7102 - val_loss: 1.1754 - val_accuracy: 0.6794\n",
      "Epoch 35/40\n",
      "227/227 [==============================] - 0s 915us/steposs: 0.9968 - accura\n",
      "2036/2036 [==============================] - 5s 3ms/step - loss: 0.9966 - accuracy: 0.7106 - val_loss: 1.1905 - val_accuracy: 0.6754\n",
      "Epoch 36/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 0.9919 \n",
      "2036/2036 [==============================] - 6s 3ms/step - loss: 0.9919 - accuracy: 0.7116 - val_loss: 1.1626 - val_accuracy: 0.6833\n",
      "Epoch 37/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 0.9854 - ac\n",
      "Epoch 37 - F1 Score: 0.6815\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384, 0.6348785953994661, 0.6462574309033058, 0.6265552948336212, 0.6417515460048598, 0.6483553787627528, 0.6513983357221315, 0.6610218959838702, 0.6590553504489519, 0.6598318937146613, 0.6535911232134137, 0.6515788929148386, 0.66683572272253, 0.6696826282057595, 0.6684889703230777, 0.6724607067686212, 0.6715293190072162, 0.667269965311054, 0.6741365769700944, 0.6700199544053506, 0.6678182995052413, 0.6768737172876371, 0.6667157880394359, 0.6803986176238958, 0.6710942622427793, 0.6785084562421844, 0.6749746034614327, 0.6670774559710664, 0.6649883990338616, 0.6670127140932592, 0.6699621896736274, 0.6815143232241861]\n",
      "2036/2036 [==============================] - 7s 3ms/step - loss: 0.9860 - accuracy: 0.7155 - val_loss: 1.1362 - val_accuracy: 0.6910\n",
      "Epoch 38/40\n",
      "227/227 [==============================] - 0s 2ms/step loss: 0.9857 \n",
      "Epoch 38 - F1 Score: 0.6847\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384, 0.6348785953994661, 0.6462574309033058, 0.6265552948336212, 0.6417515460048598, 0.6483553787627528, 0.6513983357221315, 0.6610218959838702, 0.6590553504489519, 0.6598318937146613, 0.6535911232134137, 0.6515788929148386, 0.66683572272253, 0.6696826282057595, 0.6684889703230777, 0.6724607067686212, 0.6715293190072162, 0.667269965311054, 0.6741365769700944, 0.6700199544053506, 0.6678182995052413, 0.6768737172876371, 0.6667157880394359, 0.6803986176238958, 0.6710942622427793, 0.6785084562421844, 0.6749746034614327, 0.6670774559710664, 0.6649883990338616, 0.6670127140932592, 0.6699621896736274, 0.6815143232241861, 0.6847112268680517]\n",
      "2036/2036 [==============================] - 8s 4ms/step - loss: 0.9863 - accuracy: 0.7140 - val_loss: 1.1563 - val_accuracy: 0.6890\n",
      "Epoch 39/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 0.9826 - ac\n",
      "Epoch 39 - F1 Score: 0.6885\n",
      "Saved best model\n",
      "[0.5107091911759324, 0.573418450490414, 0.5817562128291929, 0.6093243620623386, 0.6215900727922613, 0.6258220901438384, 0.6348785953994661, 0.6462574309033058, 0.6265552948336212, 0.6417515460048598, 0.6483553787627528, 0.6513983357221315, 0.6610218959838702, 0.6590553504489519, 0.6598318937146613, 0.6535911232134137, 0.6515788929148386, 0.66683572272253, 0.6696826282057595, 0.6684889703230777, 0.6724607067686212, 0.6715293190072162, 0.667269965311054, 0.6741365769700944, 0.6700199544053506, 0.6678182995052413, 0.6768737172876371, 0.6667157880394359, 0.6803986176238958, 0.6710942622427793, 0.6785084562421844, 0.6749746034614327, 0.6670774559710664, 0.6649883990338616, 0.6670127140932592, 0.6699621896736274, 0.6815143232241861, 0.6847112268680517, 0.6884905163217677]\n",
      "2036/2036 [==============================] - 7s 4ms/step - loss: 0.9830 - accuracy: 0.7149 - val_loss: 1.1306 - val_accuracy: 0.6960\n",
      "Epoch 40/40\n",
      "227/227 [==============================] - 0s 1ms/step loss: 0.9789 - accu\n",
      "2036/2036 [==============================] - 5s 2ms/step - loss: 0.9784 - accuracy: 0.7167 - val_loss: 1.1537 - val_accuracy: 0.6902\n",
      "402/402 [==============================] - 1s 2ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         119     0.8693    0.4290    0.5745      1070\n",
      "         120     0.3403    0.6633    0.4498       196\n",
      "         125     0.7273    0.8421    0.7805       532\n",
      "         134     0.8889    0.4211    0.5714        19\n",
      "         190     0.7054    0.8500    0.7710       200\n",
      "          20     0.5226    0.2284    0.3179       810\n",
      "         200     0.5746    0.6136    0.5934       590\n",
      "         203     0.3077    0.5926    0.4051        27\n",
      "          22     0.7831    0.8919    0.8339       518\n",
      "         269     0.3071    0.3679    0.3348       106\n",
      "         276     0.2553    0.3750    0.3038        64\n",
      "         287     0.4712    0.6035    0.5292       285\n",
      "         295     0.5600    0.6914    0.6188        81\n",
      "         306     0.2632    0.1064    0.1515        94\n",
      "         312     0.1774    0.2619    0.2115        42\n",
      "         319     0.3939    0.5098    0.4444        51\n",
      "         326     0.1613    0.1613    0.1613        31\n",
      "         327     0.2391    0.6286    0.3465        35\n",
      "         345     0.2500    0.1538    0.1905        26\n",
      "         347     0.2830    0.6250    0.3896        24\n",
      "         352     0.5767    0.9051    0.7045       453\n",
      "         362     0.6957    0.7869    0.7385       122\n",
      "         400     0.2767    0.6377    0.3860       138\n",
      "         401     0.6286    0.4231    0.5057        52\n",
      "         415     0.6471    0.7857    0.7097        42\n",
      "         416     0.9082    0.8523    0.8794       325\n",
      "         426     0.8235    0.3333    0.4746        42\n",
      "         427     0.5079    0.7273    0.5981        44\n",
      "         434     0.6556    0.8144    0.7264       194\n",
      "         476     0.5372    0.8744    0.6655       223\n",
      "         502     0.3370    0.8505    0.4828       107\n",
      "         522     0.4270    0.4222    0.4246        90\n",
      "         532     0.3662    0.5909    0.4522        44\n",
      "          59     0.5238    0.8073    0.6354       109\n",
      "         601     0.6914    0.7887    0.7368        71\n",
      "         611     0.5283    0.9130    0.6693        92\n",
      "         617     0.4259    0.6053    0.5000        38\n",
      "         639     0.4688    0.5357    0.5000        28\n",
      "         668     0.0000    0.0000    0.0000        45\n",
      "         732     0.1727    0.2449    0.2025        98\n",
      "          74     0.1418    0.2676    0.1854        71\n",
      "         755     0.1500    0.2143    0.1765        28\n",
      "          77     0.6133    0.3108    0.4126       148\n",
      "         770     0.2807    0.2712    0.2759        59\n",
      "         772     0.5556    0.2941    0.3846        34\n",
      "          78     0.6343    0.6622    0.6479       296\n",
      "         787     0.6143    0.6674    0.6397       890\n",
      "          79     0.9870    0.6742    0.8012      2256\n",
      "         798     0.6744    0.6744    0.6744       129\n",
      "         835     0.3846    0.7317    0.5042        41\n",
      "         843     0.5909    0.7647    0.6667        34\n",
      "         862     0.5472    0.6318    0.5865       220\n",
      "         863     0.2044    0.2373    0.2196       118\n",
      "          89     0.9888    0.8339    0.9048       957\n",
      "         908     0.4444    0.5000    0.4706        24\n",
      "         918     0.9189    0.7556    0.8293        90\n",
      "          94     0.4224    0.5685    0.4847       292\n",
      "\n",
      "    accuracy                         0.6350     12845\n",
      "   macro avg     0.4988    0.5610    0.5059     12845\n",
      "weighted avg     0.6923    0.6350    0.6390     12845\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['label_encoder_train_terms.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import joblib\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class F1ScoreCallback(Callback):\n",
    "    def __init__(self, X_val, y_val):\n",
    "        super(F1ScoreCallback, self).__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.best_f1 = 0.0\n",
    "        self.best_model = None\n",
    "        self.f1_scores = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_val_pred = np.argmax(self.model.predict(self.X_val), axis=1)\n",
    "        f1 = f1_score(self.y_val, y_val_pred, average='weighted')\n",
    "        self.f1_scores.append(f1)\n",
    "        \n",
    "\n",
    "        if f1 > self.best_f1:\n",
    "            self.best_f1 = f1\n",
    "            self.best_model = self.model\n",
    "            print(f\"Epoch {epoch + 1} - F1 Score: {f1:.4f}\")\n",
    "            print(\"Saved best model\")\n",
    "            print(self.f1_scores)\n",
    "\n",
    "with open('train_bert_comp.pickle', 'rb') as f1:\n",
    "    balanced = pickle.load(f1)\n",
    "\n",
    "with open('bert_comparison_test.pickle', 'rb') as f2:\n",
    "    unbalanced = pickle.load(f2)\n",
    "\n",
    "train = np.array([item['cve_terms_bert_mean'].tolist() for item in balanced if item['cwe'] != 'None'])\n",
    "\n",
    "test = np.array([item['cwe'] for item in balanced if item['cwe'] != 'None'])\n",
    "np.random.seed(42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(train,test,test_size=0.1,random_state=42)\n",
    "\n",
    "X_test = np.array([item['cve_terms_bert_mean'].tolist() for item in unbalanced if item['cwe'] != 'None'])\n",
    "y_test = np.array([item['cwe'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "\n",
    "label_encoder_train = LabelEncoder()\n",
    "y_train_encoded = label_encoder_train.fit_transform(y_train)\n",
    "label_encoder_test = LabelEncoder()\n",
    "y_test_encoded = label_encoder_test.fit_transform(y_test)\n",
    "\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = len(np.unique(y_train))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "f1_callback = F1ScoreCallback(X_val, label_encoder_train.transform(y_val))\n",
    "\n",
    "history = model.fit(X_train, y_train_encoded, epochs=40, batch_size=32, validation_data=(X_val, label_encoder_train.transform(y_val)), verbose=1, callbacks=[f1_callback])\n",
    "\n",
    "best_model = f1_callback.best_model\n",
    "\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model, 'best_model_terms.joblib')\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_probs = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "y_pred_original = label_encoder_train.inverse_transform(y_pred)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_original, digits=4))\n",
    "\n",
    "joblib.dump(label_encoder_train, 'label_encoder_train_terms.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference for CVE terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 [==============================] - 1s 2ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         119     0.8693    0.4290    0.5745      1070\n",
      "         120     0.3403    0.6633    0.4498       196\n",
      "         125     0.7273    0.8421    0.7805       532\n",
      "         134     0.8889    0.4211    0.5714        19\n",
      "         190     0.7054    0.8500    0.7710       200\n",
      "          20     0.5226    0.2284    0.3179       810\n",
      "         200     0.5746    0.6136    0.5934       590\n",
      "         203     0.3077    0.5926    0.4051        27\n",
      "          22     0.7831    0.8919    0.8339       518\n",
      "         269     0.3071    0.3679    0.3348       106\n",
      "         276     0.2553    0.3750    0.3038        64\n",
      "         287     0.4712    0.6035    0.5292       285\n",
      "         295     0.5600    0.6914    0.6188        81\n",
      "         306     0.2632    0.1064    0.1515        94\n",
      "         312     0.1774    0.2619    0.2115        42\n",
      "         319     0.3939    0.5098    0.4444        51\n",
      "         326     0.1613    0.1613    0.1613        31\n",
      "         327     0.2391    0.6286    0.3465        35\n",
      "         345     0.2500    0.1538    0.1905        26\n",
      "         347     0.2830    0.6250    0.3896        24\n",
      "         352     0.5767    0.9051    0.7045       453\n",
      "         362     0.6957    0.7869    0.7385       122\n",
      "         400     0.2767    0.6377    0.3860       138\n",
      "         401     0.6286    0.4231    0.5057        52\n",
      "         415     0.6471    0.7857    0.7097        42\n",
      "         416     0.9082    0.8523    0.8794       325\n",
      "         426     0.8235    0.3333    0.4746        42\n",
      "         427     0.5079    0.7273    0.5981        44\n",
      "         434     0.6556    0.8144    0.7264       194\n",
      "         476     0.5372    0.8744    0.6655       223\n",
      "         502     0.3370    0.8505    0.4828       107\n",
      "         522     0.4270    0.4222    0.4246        90\n",
      "         532     0.3662    0.5909    0.4522        44\n",
      "          59     0.5238    0.8073    0.6354       109\n",
      "         601     0.6914    0.7887    0.7368        71\n",
      "         611     0.5283    0.9130    0.6693        92\n",
      "         617     0.4259    0.6053    0.5000        38\n",
      "         639     0.4688    0.5357    0.5000        28\n",
      "         668     0.0000    0.0000    0.0000        45\n",
      "         732     0.1727    0.2449    0.2025        98\n",
      "          74     0.1418    0.2676    0.1854        71\n",
      "         755     0.1500    0.2143    0.1765        28\n",
      "          77     0.6133    0.3108    0.4126       148\n",
      "         770     0.2807    0.2712    0.2759        59\n",
      "         772     0.5556    0.2941    0.3846        34\n",
      "          78     0.6343    0.6622    0.6479       296\n",
      "         787     0.6143    0.6674    0.6397       890\n",
      "          79     0.9870    0.6742    0.8012      2256\n",
      "         798     0.6744    0.6744    0.6744       129\n",
      "         835     0.3846    0.7317    0.5042        41\n",
      "         843     0.5909    0.7647    0.6667        34\n",
      "         862     0.5472    0.6318    0.5865       220\n",
      "         863     0.2044    0.2373    0.2196       118\n",
      "          89     0.9888    0.8339    0.9048       957\n",
      "         908     0.4444    0.5000    0.4706        24\n",
      "         918     0.9189    0.7556    0.8293        90\n",
      "          94     0.4224    0.5685    0.4847       292\n",
      "\n",
      "    accuracy                         0.6350     12845\n",
      "   macro avg     0.4988    0.5610    0.5059     12845\n",
      "weighted avg     0.6923    0.6350    0.6390     12845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Save the best model\n",
    "with open('bert_comparison_test.pickle', 'rb') as f2:\n",
    "    unbalanced = pickle.load(f2)\n",
    "\n",
    "X_test = np.array([item['cve_terms_bert_mean'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "y_test = np.array([item['cwe'] for item in unbalanced if item['cwe'] != 'None'])\n",
    "\n",
    "best_model=joblib.load('best_model_terms.joblib')\n",
    "label_encoder_train=joblib.load('label_encoder_train_terms.joblib')\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_probs = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "y_pred_original = label_encoder_train.inverse_transform(y_pred)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_original, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
